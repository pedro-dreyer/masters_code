parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.2
initial_learning_rate:0.001
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.056,1.894,1.843,1.76,1.637,1.541,1.467,1.449,1.354,1.304,1.251,1.18,1.121,1.052,1.005,0.972,0.905,0.905,0.843,0.808,0.762,0.739,0.707,0.673,0.688,0.635,0.586,0.578,0.53,0.496,0.524,0.457,0.448,0.435,0.419,0.387,0.386,0.346,0.336,0.326,0.336,0.427,0.304,0.28,0.262,0.289,0.223,0.246,0.229,0.232,0.286,0.206,0.181,0.207,0.204,0.193,0.164,0.166,0.178,0.232,0.146,0.194,0.148,0.129,0.119,0.142,0.134,0.188,0.126,0.18,0.114,0.092,0.12,0.095,0.126,0.125,0.088,0.13,0.086,0.07,0.096,0.069,0.085,0.07,0.09,0.112,0.148,0.098,0.063,0.071,0.056,0.043,0.063,0.072,0.121,0.057,0.043,0.061,0.103,0.053

train_acc1
18.2,23.95,26.42,30.74,33.93,37.01,41.27,42.85,47.94,51.17,54.6,57.69,59.93,62.67,64.18,65.24,68.73,69.34,71.3,71.81,73.86,74.24,75.9,76.77,76.92,77.81,80.48,80.65,81.59,83.6,82.53,84.7,84.84,85.59,85.77,86.9,86.95,88.69,88.74,88.92,88.61,86.22,89.98,90.82,91.28,90.35,92.45,91.9,92.67,92.55,90.5,92.77,94.27,93.27,93.3,93.69,94.57,94.54,95.11,92.51,95.59,93.64,95.22,95.95,96.04,95.25,95.73,93.79,95.93,94.3,96.37,96.99,96.31,97.11,95.99,96.2,97.24,95.89,97.01,97.86,96.85,97.71,97.11,97.75,97.15,97.27,95.49,96.86,97.95,97.68,98.12,98.69,97.94,97.84,96.39,98.07,98.57,98.42,96.82,98.3

val_acc1
19.02,25.38,24.76,30.27,34.79,38.5,39.6,42.28,43.32,39.1,49.46,51.37,57.04,56.71,53.66,63.73,62.79,66.45,64.31,68.17,64.93,69.82,66.99,69.66,70.65,71.27,72.47,73.91,71.14,70.85,69.07,74.0,75.47,71.51,74.99,75.13,74.37,75.61,77.05,77.23,74.55,77.76,76.92,77.77,75.09,75.13,77.46,78.18,76.96,77.6,78.14,77.28,77.87,77.39,78.44,76.34,77.36,78.81,78.38,78.81,78.64,78.57,78.64,78.05,78.51,80.66,79.56,79.12,78.09,79.86,79.96,79.75,79.98,80.78,79.01,79.46,79.34,79.55,79.15,80.72,79.77,79.71,80.0,79.99,80.12,79.52,80.02,79.78,79.67,80.91,79.84,80.52,80.48,80.31,81.0,80.15,80.56,80.47,80.28,79.88

val_loss
2.078,1.91,2.091,1.807,1.611,1.619,1.531,1.569,1.504,1.595,1.482,1.389,1.262,1.243,1.539,1.067,1.117,0.967,1.069,0.945,1.086,0.915,1.023,0.909,0.929,0.913,0.892,0.807,0.913,1.017,1.061,0.845,0.825,0.994,0.837,0.867,0.871,0.859,0.785,0.822,1.017,0.762,0.813,0.799,0.988,0.967,0.862,0.879,0.882,0.9,0.826,0.934,0.906,0.976,0.872,0.994,0.948,0.878,0.908,0.882,0.998,0.889,0.941,1.003,0.996,0.82,0.895,0.91,1.01,0.898,0.873,0.958,0.895,0.909,1.001,0.966,0.974,0.954,1.029,0.927,1.005,0.964,0.963,0.995,0.959,0.963,0.939,0.915,1.016,0.919,1.016,1.032,0.983,0.997,0.909,1.009,1.017,1.045,0.92,1.037

learning_rate
0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001

