parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.4
initial_learning_rate:0.01
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.382,2.148,1.908,1.78,1.631,1.499,1.379,1.259,1.12,1.022,0.936,0.881,0.813,0.78,0.719,0.671,0.639,0.601,0.558,0.54,0.51,0.485,0.471,0.429,0.418,0.403,0.387,0.362,0.346,0.33,0.302,0.296,0.295,0.265,0.259,0.267,0.251,0.227,0.215,0.21,0.201,0.198,0.176,0.17,0.176,0.168,0.165,0.157,0.174,0.147,0.147,0.142,0.129,0.134,0.126,0.134,0.124,0.106,0.107,0.109,0.096,0.1,0.098,0.095,0.104,0.102,0.092,0.084,0.087,0.087,0.079,0.072,0.071,0.092,0.083,0.091,0.078,0.089,0.071,0.077,0.067,0.071,0.081,0.06,0.068,0.071,0.068,0.067,0.062,0.058,0.054,0.057,0.058,0.048,0.056,0.059,0.052,0.057,0.061,0.056

train_acc1
11.69,15.52,22.92,29.295,36.145,41.8,47.73,52.99,59.225,62.985,66.64,69.025,71.805,73.26,75.52,77.16,78.335,79.98,81.695,82.365,83.025,84.075,84.36,85.945,86.42,87.0,87.35,88.26,88.585,89.225,90.055,90.235,90.355,91.47,91.445,91.45,91.835,92.77,92.705,93.09,93.445,93.515,94.33,94.525,94.485,94.735,94.54,95.22,94.475,95.18,95.32,95.36,96.005,95.805,96.09,95.7,96.095,96.65,96.575,96.55,96.925,96.835,96.9,97.095,96.78,96.79,97.045,97.265,97.33,97.3,97.57,97.885,97.865,97.15,97.315,97.115,97.555,97.18,97.9,97.68,97.9,97.82,97.575,98.185,97.985,97.835,97.94,97.94,98.05,98.235,98.39,98.175,98.175,98.65,98.24,98.22,98.35,98.335,98.235,98.305

val_acc1
11.31,16.81,26.69,25.92,36.2,43.19,47.03,47.87,49.66,60.3,63.98,55.89,65.89,72.28,72.93,72.7,70.69,73.72,73.64,75.03,75.73,72.07,78.96,78.84,77.46,77.88,79.16,80.28,81.28,81.19,79.29,79.61,80.05,81.88,80.93,81.56,82.4,81.69,81.64,82.43,80.69,82.5,81.2,82.18,82.78,82.62,82.23,80.59,82.54,83.18,82.52,82.82,82.82,83.48,82.89,82.9,83.89,83.76,84.09,83.95,83.01,82.94,83.48,83.88,84.34,83.14,83.35,84.26,83.49,83.36,84.48,84.37,84.13,84.63,83.2,83.32,82.93,84.16,83.44,83.53,83.14,82.98,82.94,84.33,83.88,83.8,84.29,83.37,84.56,84.67,84.62,84.19,84.57,85.1,83.8,84.11,83.8,84.98,84.67,83.17

val_loss
2.268,2.036,1.829,2.143,1.649,1.544,1.418,1.433,1.638,1.104,1.056,1.397,1.094,0.823,0.824,0.796,0.92,0.89,0.824,0.83,0.753,0.937,0.675,0.678,0.838,0.768,0.747,0.673,0.639,0.65,0.792,0.73,0.709,0.632,0.71,0.708,0.651,0.685,0.693,0.697,0.72,0.683,0.753,0.772,0.677,0.705,0.745,0.833,0.749,0.694,0.688,0.714,0.73,0.706,0.763,0.718,0.644,0.66,0.706,0.7,0.786,0.747,0.732,0.731,0.688,0.829,0.69,0.708,0.767,0.78,0.729,0.729,0.738,0.72,0.796,0.78,0.9,0.778,0.759,0.819,0.842,0.811,0.861,0.742,0.72,0.803,0.776,0.857,0.78,0.763,0.713,0.761,0.764,0.75,0.818,0.765,0.825,0.727,0.751,0.822

learning_rate
0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01

