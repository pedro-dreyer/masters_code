parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.6
initial_learning_rate:0.01
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.336,1.951,1.787,1.544,1.344,1.17,1.031,0.918,0.834,0.767,0.718,0.652,0.619,0.575,0.541,0.521,0.487,0.465,0.44,0.418,0.394,0.379,0.362,0.33,0.326,0.314,0.299,0.285,0.271,0.259,0.257,0.24,0.232,0.219,0.222,0.202,0.202,0.194,0.175,0.179,0.173,0.167,0.156,0.15,0.151,0.14,0.141,0.132,0.133,0.125,0.124,0.12,0.11,0.115,0.114,0.107,0.1,0.098,0.1,0.097,0.109,0.086,0.085,0.086,0.087,0.083,0.078,0.081,0.074,0.076,0.075,0.073,0.069,0.074,0.07,0.066,0.068,0.07,0.064,0.066,0.062,0.073,0.054,0.061,0.056,0.06,0.057,0.052,0.056,0.056,0.056,0.049,0.047,0.064,0.052,0.045,0.05,0.051,0.05,0.051

train_acc1
12.523,22.177,29.233,40.173,50.007,57.953,63.593,67.717,70.947,73.55,75.74,78.203,79.437,80.93,82.133,82.97,84.187,84.927,85.583,86.273,87.267,87.857,88.303,89.367,89.543,89.933,90.42,90.84,91.427,91.683,91.6,92.233,92.45,92.97,92.88,93.55,93.603,93.967,94.577,94.317,94.573,94.773,95.017,95.273,95.04,95.617,95.51,95.86,95.807,96.047,96.053,96.15,96.413,96.443,96.363,96.6,96.867,96.937,97.043,96.913,96.8,97.31,97.263,97.243,97.3,97.35,97.63,97.44,97.733,97.663,97.767,97.703,97.927,97.783,97.78,97.907,97.95,97.877,98.09,98.033,98.15,97.847,98.37,98.173,98.353,98.14,98.24,98.367,98.207,98.293,98.217,98.53,98.577,98.047,98.423,98.623,98.487,98.457,98.523,98.377

val_acc1
13.79,23.4,34.0,42.59,50.95,59.93,60.51,67.63,69.9,70.56,72.51,71.9,70.64,77.83,77.14,77.48,80.0,79.53,80.33,80.36,83.32,83.44,79.99,83.07,83.74,82.53,84.03,83.7,84.75,84.29,84.88,85.41,85.1,85.4,83.72,84.97,85.79,85.37,84.42,83.95,84.76,85.77,85.97,85.87,85.54,85.17,85.82,84.29,85.8,85.88,86.37,85.52,86.22,85.89,85.5,86.41,86.35,86.28,86.51,86.44,86.18,86.17,86.42,86.33,86.41,87.4,86.53,86.8,86.53,85.98,86.65,87.09,86.29,86.88,86.14,86.01,86.33,86.74,86.97,86.48,86.61,86.57,86.78,86.79,87.02,87.35,87.18,86.3,86.81,86.28,86.86,87.21,86.98,86.65,87.23,87.1,87.27,87.09,87.29,87.01

val_loss
2.183,2.445,1.663,1.512,1.341,1.134,1.197,0.953,0.903,0.899,0.876,0.902,0.952,0.71,0.732,0.743,0.657,0.689,0.632,0.678,0.538,0.555,0.734,0.579,0.56,0.584,0.542,0.549,0.541,0.532,0.524,0.526,0.562,0.52,0.59,0.565,0.526,0.536,0.607,0.633,0.619,0.563,0.54,0.551,0.584,0.566,0.561,0.662,0.59,0.634,0.568,0.61,0.631,0.552,0.625,0.607,0.566,0.612,0.576,0.637,0.597,0.651,0.579,0.58,0.573,0.569,0.613,0.603,0.605,0.64,0.608,0.567,0.638,0.636,0.655,0.631,0.634,0.602,0.613,0.673,0.644,0.648,0.621,0.627,0.643,0.65,0.597,0.689,0.623,0.676,0.635,0.622,0.62,0.656,0.616,0.631,0.67,0.66,0.643,0.637

learning_rate
0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01

