parameters
adam_lr:0.001
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:True
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.2
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
1.995,1.876,1.833,1.787,1.677,1.591,1.496,1.459,1.387,1.291,1.193,1.087,1.024,0.977,0.901,0.882,0.844,0.79,0.758,0.744,0.699,0.668,0.623,0.586,0.591,0.537,0.536,0.512,0.479,0.454,0.436,0.423,0.383,0.378,0.4,0.364,0.398,0.387,0.348,0.281,0.289,0.281,0.269,0.332,0.231,0.239,0.229,0.201,0.24,0.195,0.226,0.209,0.223,0.175,0.172,0.173,0.132,0.136,0.167,0.291,0.134,0.137,0.12,0.134,0.117,0.099,0.103,0.11,0.093,0.103,0.113,0.128,0.08,0.097,0.109,0.094,0.079,0.094,0.166,0.09,0.081,0.07,0.102,0.061,0.086,0.107,0.09,0.071,0.053,0.081,0.299,0.126,0.061,0.054,0.056,0.079,0.061,0.071,0.05,0.053

train_acc1
18.76,22.01,24.6,27.99,31.89,34.59,38.7,41.39,44.94,51.12,55.83,60.43,62.92,64.68,67.69,68.17,69.63,71.9,73.45,73.35,75.4,76.8,77.6,79.44,79.7,81.31,81.99,82.54,83.41,84.42,84.99,85.65,87.08,87.1,86.79,88.21,86.88,87.08,87.98,90.67,90.54,90.41,91.4,89.34,92.26,92.01,92.41,93.37,91.77,93.64,92.85,93.13,92.6,93.98,94.44,94.16,95.57,95.48,95.1,90.92,95.55,95.71,95.96,95.71,95.87,96.74,96.61,96.17,97.04,96.95,96.73,96.08,97.22,96.95,96.62,97.03,97.38,96.99,94.95,97.09,97.46,97.92,96.63,97.92,97.25,96.77,97.47,97.73,98.21,97.66,90.45,96.14,98.14,98.2,98.35,97.58,98.13,97.87,98.41,98.34

val_acc1
17.05,24.2,25.2,27.7,34.2,30.55,37.15,40.85,44.3,51.9,51.8,59.95,59.8,61.8,62.9,63.7,64.25,67.2,67.3,65.95,67.05,68.7,70.2,66.3,69.15,73.35,70.25,70.8,73.2,71.4,76.0,73.1,75.05,75.0,74.45,77.5,73.15,74.95,76.05,76.75,77.25,73.8,75.65,79.2,76.55,76.55,77.1,74.9,78.0,77.65,79.4,75.4,77.1,75.45,76.4,77.4,75.35,77.9,76.05,78.4,78.4,77.35,79.45,79.3,78.7,77.0,77.95,79.7,78.75,77.0,80.75,79.9,79.5,77.15,77.25,80.35,78.95,78.65,78.2,78.55,80.3,78.0,79.35,78.45,77.55,78.05,79.4,78.5,77.5,78.0,77.65,79.2,79.75,79.85,79.75,78.7,80.35,78.8,79.3,79.8

val_loss
1.928,1.919,1.844,1.813,1.629,2.066,1.752,1.593,1.442,1.343,1.387,1.161,1.11,1.081,1.086,1.029,1.027,0.971,0.933,1.079,1.009,0.97,0.924,1.111,0.975,0.802,0.978,0.9,0.877,0.949,0.768,0.861,0.87,0.836,0.825,0.729,0.924,0.853,0.838,0.839,0.821,0.908,0.867,0.743,0.874,0.885,0.862,1.024,0.777,0.824,0.773,0.949,0.937,0.972,0.947,0.911,1.037,0.997,0.992,0.795,0.927,0.904,0.869,0.919,0.883,1.013,1.013,0.885,0.97,1.035,0.885,0.896,0.95,1.097,0.984,0.872,0.97,0.992,0.931,0.941,0.87,1.148,0.911,1.061,1.076,1.085,1.009,1.002,1.23,1.163,0.88,0.885,0.994,0.998,0.991,1.04,1.046,0.984,1.027,1.025

learning_rate
0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001

