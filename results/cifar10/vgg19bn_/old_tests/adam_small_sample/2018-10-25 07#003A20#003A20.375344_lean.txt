parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.1
initial_learning_rate:0.0003
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.017,1.785,1.683,1.577,1.491,1.465,1.411,1.35,1.35,1.366,1.269,1.242,1.298,1.158,1.13,1.021,0.986,0.956,0.898,0.879,0.837,0.827,0.827,0.782,0.762,0.821,0.661,0.664,0.763,0.675,0.591,0.691,0.759,0.54,0.513,0.513,0.516,0.727,0.515,0.495,0.431,0.431,0.374,0.444,0.553,0.575,0.364,0.43,0.371,0.331,0.352,0.377,0.575,0.402,0.378,0.331,0.248,0.265,0.448,0.476,0.402,0.268,0.239,0.297,0.233,0.314,0.206,0.249,0.255,0.352,0.207,0.26,0.299,0.241,0.352,0.174,0.16,0.412,0.262,0.14,0.22,0.237,0.222,0.233,0.229,0.247,0.229,0.226,0.327,0.156,0.135,0.168,0.196,0.202,0.122,0.1,0.158,0.284,0.125,0.237

train_acc1
20.58,28.06,32.48,37.04,41.8,43.64,45.36,47.78,49.28,48.62,54.12,54.72,52.38,57.82,60.04,63.28,63.76,66.1,67.9,69.04,70.16,70.68,71.06,72.94,72.8,71.04,76.9,76.62,73.74,75.9,79.66,76.62,73.24,80.08,81.78,82.56,82.82,74.8,81.94,82.86,85.16,85.32,88.02,84.84,81.16,81.4,88.12,85.38,87.86,88.6,89.44,88.48,82.02,87.12,87.52,89.26,92.28,92.12,88.32,85.78,87.72,90.96,92.78,89.6,92.3,89.54,93.86,92.48,91.4,88.9,93.6,92.3,92.22,94.02,88.7,94.42,94.72,87.96,91.66,95.52,92.92,92.92,93.3,93.76,93.54,94.22,92.92,94.78,89.94,94.9,96.84,95.1,93.96,93.34,95.94,96.9,95.74,90.96,96.3,93.12

val_acc1
23.85,31.08,33.52,36.07,38.9,38.58,42.15,40.61,42.93,45.09,51.49,48.45,49.7,52.02,57.15,55.92,53.95,56.92,62.68,59.33,56.88,57.22,56.15,59.4,58.11,64.09,63.44,56.16,64.77,63.64,62.25,64.83,67.44,65.36,69.25,65.58,66.6,62.76,69.76,66.64,66.5,69.16,66.21,69.84,66.2,69.57,69.82,69.21,69.39,67.81,70.16,67.25,70.28,70.54,70.09,70.27,69.31,68.68,66.46,70.24,72.03,71.06,72.11,71.85,70.93,71.26,72.01,71.46,70.51,70.09,70.7,72.25,71.85,70.78,72.08,71.9,72.46,72.59,72.06,72.42,71.64,72.83,72.74,72.23,73.54,73.64,71.71,71.84,71.72,73.37,73.0,71.34,71.86,73.32,74.64,73.6,72.83,71.98,71.48,72.9

val_loss
2.297,1.728,1.774,1.68,1.562,1.684,1.554,1.631,1.572,1.468,1.32,1.448,1.356,1.338,1.21,1.219,1.348,1.29,1.079,1.212,1.383,1.418,1.328,1.249,1.267,1.042,1.11,1.582,1.105,1.121,1.266,1.193,0.962,1.134,0.973,1.118,1.116,1.209,0.97,1.126,1.227,1.043,1.29,1.046,1.237,1.003,1.038,1.051,1.053,1.282,1.141,1.227,1.002,1.001,1.065,1.063,1.197,1.256,1.399,1.016,1.016,1.091,1.057,1.086,1.168,1.085,1.098,1.174,1.218,1.159,1.195,1.109,1.06,1.189,1.085,1.138,1.143,1.054,1.086,1.177,1.203,1.124,1.094,1.133,1.083,1.026,1.09,1.154,1.099,1.118,1.157,1.341,1.16,1.087,1.088,1.203,1.253,1.125,1.287,1.172

learning_rate
0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003

