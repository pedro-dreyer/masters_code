parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.1
initial_learning_rate:0.0001
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.122,1.833,1.717,1.605,1.481,1.429,1.371,1.284,1.242,1.175,1.171,1.139,1.075,1.013,0.986,0.919,0.895,0.895,0.856,0.799,0.788,0.718,0.751,0.766,0.723,0.647,0.595,0.682,0.623,0.536,0.567,0.652,0.58,0.465,0.424,0.453,0.428,0.413,0.425,0.455,0.431,0.29,0.285,0.356,0.294,0.522,0.329,0.316,0.405,0.325,0.272,0.355,0.311,0.267,0.222,0.263,0.237,0.242,0.438,0.481,0.284,0.323,0.219,0.22,0.171,0.215,0.157,0.182,0.378,0.262,0.126,0.158,0.221,0.219,0.243,0.326,0.19,0.145,0.143,0.101,0.161,0.3,0.158,0.133,0.192,0.288,0.248,0.174,0.199,0.131,0.199,0.184,0.148,0.126,0.067,0.082,0.118,0.166,0.089,0.127

train_acc1
18.84,27.06,32.12,37.48,44.1,46.18,48.68,51.34,53.64,56.34,59.0,59.08,61.08,62.56,65.32,66.96,67.88,69.2,68.6,71.78,71.24,74.52,74.96,73.04,75.42,77.24,80.06,76.1,78.78,81.26,80.54,77.62,79.64,83.62,85.02,84.68,85.48,85.6,86.14,84.62,84.32,89.96,90.84,87.38,90.96,82.82,88.66,89.78,86.24,88.92,91.94,88.76,90.6,91.0,92.54,91.94,92.14,93.1,86.74,84.92,91.86,89.36,93.14,92.7,94.62,92.52,95.16,95.1,88.86,91.18,96.3,95.22,94.3,93.52,92.68,90.58,93.8,95.2,95.38,96.86,95.64,90.5,95.1,96.98,93.8,92.94,92.94,95.3,93.46,96.3,94.26,94.8,95.64,96.1,97.98,97.32,96.48,95.02,97.36,97.14

val_acc1
25.17,30.46,36.51,39.41,39.52,42.06,43.71,43.24,46.51,49.49,52.1,49.85,56.03,57.71,58.27,54.5,57.49,59.07,55.85,60.88,60.0,58.38,55.22,62.1,57.39,61.61,59.88,59.11,62.95,64.55,61.87,63.24,62.47,63.41,65.03,62.73,65.38,59.9,65.32,62.88,65.16,65.74,65.58,64.21,62.94,63.7,65.52,63.74,64.78,66.04,65.39,59.28,66.6,67.81,66.95,64.75,66.02,66.51,64.7,65.55,65.24,66.34,67.19,67.99,68.71,66.73,66.56,66.8,66.6,67.6,66.57,67.49,65.42,67.81,65.41,66.62,66.91,68.89,67.39,68.58,67.08,67.88,69.65,67.95,66.43,68.03,66.88,68.03,67.0,68.48,67.4,68.17,69.03,67.67,68.61,69.32,67.94,68.13,68.82,68.48

val_loss
1.906,1.73,1.612,1.565,1.596,1.542,1.455,1.532,1.458,1.363,1.336,1.39,1.25,1.193,1.189,1.364,1.221,1.194,1.339,1.158,1.177,1.297,1.397,1.112,1.267,1.191,1.28,1.292,1.176,1.143,1.279,1.175,1.188,1.22,1.182,1.26,1.182,1.453,1.178,1.317,1.19,1.213,1.246,1.306,1.379,1.267,1.24,1.313,1.267,1.279,1.286,1.701,1.218,1.18,1.251,1.391,1.284,1.322,1.338,1.251,1.295,1.237,1.272,1.249,1.258,1.299,1.358,1.386,1.317,1.252,1.337,1.368,1.442,1.297,1.404,1.265,1.263,1.253,1.325,1.304,1.458,1.28,1.198,1.332,1.432,1.299,1.31,1.27,1.316,1.28,1.366,1.287,1.238,1.345,1.335,1.358,1.434,1.404,1.37,1.449

learning_rate
0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001

