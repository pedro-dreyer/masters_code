parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.1
initial_learning_rate:0.005
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.394,2.268,2.244,2.173,2.058,2.015,1.965,1.935,1.904,1.878,1.894,1.842,1.817,1.789,1.796,1.734,1.698,1.657,1.583,1.682,1.582,1.54,1.496,1.499,1.468,1.424,1.398,1.39,1.335,1.317,1.292,1.265,1.257,1.287,1.153,1.129,1.156,1.077,1.066,1.076,1.107,0.987,0.994,1.063,0.993,0.972,0.875,0.903,0.916,0.862,0.86,0.789,0.826,0.76,0.758,0.78,0.689,0.735,0.77,0.785,0.783,0.683,0.607,0.737,0.613,0.561,0.662,0.578,0.608,0.578,0.514,0.625,0.585,0.601,0.454,0.431,0.493,0.413,0.429,0.431,0.412,0.389,0.384,0.364,0.355,0.488,0.419,0.35,0.364,0.391,0.362,0.265,0.236,0.241,0.429,0.442,0.307,0.361,0.302,0.346

train_acc1
11.44,13.56,13.88,16.42,18.76,19.58,19.94,21.78,23.54,25.68,26.26,27.36,28.24,30.08,28.18,30.9,32.9,34.18,37.58,32.12,36.8,38.94,40.36,41.86,42.82,45.74,46.54,47.16,49.12,50.78,50.96,53.94,53.28,51.3,56.92,58.9,58.52,60.98,61.5,61.42,59.12,63.5,64.1,61.96,64.68,65.26,68.28,67.8,67.08,69.22,70.48,71.48,70.48,73.52,74.14,72.58,75.18,74.54,76.42,73.16,74.46,76.1,78.84,74.3,79.1,79.78,77.4,80.08,79.7,80.54,82.04,79.24,81.84,80.86,85.68,84.92,83.62,86.26,85.36,85.88,86.06,88.52,87.24,89.92,89.04,86.28,86.14,89.42,89.08,87.84,88.22,91.42,91.96,92.22,87.24,85.5,90.38,87.98,91.18,89.14

val_acc1
12.19,15.77,11.62,18.05,17.77,18.6,22.12,23.08,21.64,25.21,26.59,24.8,25.85,25.13,28.57,31.18,31.64,32.59,31.5,33.12,33.64,36.98,36.38,36.41,37.84,34.71,36.95,44.88,45.81,40.53,40.69,43.79,40.72,51.99,53.52,54.43,54.05,47.33,56.7,45.55,50.77,56.63,56.72,58.7,57.15,57.23,59.19,55.0,58.3,57.39,56.68,58.62,62.75,62.92,61.83,62.21,62.97,64.7,61.42,64.44,64.27,65.73,62.87,65.86,68.57,67.37,67.47,68.42,61.54,64.86,65.41,65.78,61.44,69.96,67.16,66.65,70.83,69.78,68.71,67.86,71.19,69.87,70.69,70.46,69.39,70.49,70.1,69.24,72.02,71.85,70.05,71.09,69.4,70.99,71.29,70.58,71.3,72.25,68.01,70.54

val_loss
2.274,2.953,2.308,2.107,2.066,2.045,1.96,1.88,1.907,1.908,1.882,1.857,2.058,1.962,1.927,1.814,1.743,1.716,1.817,1.666,1.839,1.678,1.642,1.641,1.683,1.707,1.577,1.547,1.483,1.728,1.566,1.715,1.717,1.317,1.31,1.282,1.257,1.568,1.287,1.629,1.475,1.244,1.297,1.153,1.297,1.247,1.182,1.426,1.289,1.384,1.384,1.47,1.158,1.126,1.288,1.125,1.22,1.062,1.368,1.163,1.163,1.05,1.287,1.075,0.995,1.098,1.044,1.018,1.404,1.253,1.254,1.186,1.481,0.997,1.115,1.216,0.987,1.046,1.13,1.149,1.056,1.187,1.119,1.146,1.187,1.064,1.1,1.26,1.085,1.057,1.197,1.158,1.332,1.274,1.092,1.047,1.132,1.076,1.284,1.244

learning_rate
0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005,0.005

