parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.1
initial_learning_rate:0.0005
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.05,1.899,1.876,1.834,1.752,1.753,1.641,1.545,1.542,1.502,1.46,1.463,1.43,1.301,1.289,1.241,1.172,1.12,1.079,1.063,1.053,1.033,0.979,0.943,0.922,0.993,0.843,0.851,0.847,0.797,0.713,0.785,0.901,0.702,0.628,0.595,0.665,0.631,0.604,0.588,0.572,0.527,0.459,0.67,0.542,0.52,0.404,0.63,0.55,0.441,0.439,0.514,0.453,0.391,0.379,0.427,0.331,0.283,0.498,0.559,0.419,0.431,0.293,0.356,0.387,0.295,0.222,0.26,0.32,0.254,0.244,0.315,0.318,0.286,0.34,0.293,0.215,0.17,0.201,0.136,0.153,0.228,0.246,0.177,0.283,0.236,0.395,0.219,0.228,0.161,0.19,0.28,0.163,0.099,0.17,0.373,0.346,0.184,0.122,0.222

train_acc1
17.22,21.32,24.82,25.28,29.84,31.58,34.14,36.4,38.08,39.84,44.38,43.44,44.52,51.16,52.06,53.74,56.08,58.6,60.78,61.74,61.6,62.38,65.46,67.1,67.0,64.88,70.72,69.56,69.9,71.8,75.02,73.78,68.38,74.36,77.34,78.44,77.52,78.18,78.84,79.64,79.56,80.52,83.3,77.04,80.52,81.66,86.04,78.82,81.18,84.0,85.98,83.04,84.44,86.72,88.12,85.96,88.98,90.6,85.04,82.42,87.64,85.64,89.84,87.82,87.84,89.28,93.68,91.32,89.44,90.78,92.44,90.6,90.4,91.76,89.12,90.72,92.64,94.22,93.0,95.56,95.08,93.36,92.8,95.72,91.5,93.36,87.52,93.74,93.0,95.1,94.26,91.12,94.68,96.92,95.28,88.78,89.74,93.86,97.04,94.12

val_acc1
20.64,23.71,27.37,22.98,28.75,28.29,32.54,38.97,37.94,38.29,40.6,33.29,44.05,45.71,48.93,41.52,48.87,50.39,54.76,52.69,58.12,52.43,54.14,56.41,52.35,60.86,59.46,57.53,61.8,60.33,57.8,58.79,55.58,65.6,66.39,64.39,65.77,65.99,65.65,64.83,59.06,68.13,68.92,67.49,67.59,67.33,69.96,66.28,69.34,68.58,68.74,67.85,68.22,70.31,69.36,70.44,70.23,70.39,68.65,68.88,69.11,71.76,69.58,71.55,71.13,72.12,72.59,70.18,71.51,70.57,72.41,72.18,72.67,72.23,70.49,72.37,72.64,73.49,72.65,73.14,72.61,73.62,73.62,72.64,71.5,72.21,71.61,71.84,70.74,73.42,71.45,73.13,72.69,74.5,72.12,70.34,72.51,73.67,73.04,72.52

val_loss
2.336,1.874,1.902,2.032,1.846,1.992,1.732,1.564,1.625,1.705,1.595,2.021,1.452,1.533,1.418,1.672,1.518,1.534,1.241,1.371,1.203,1.45,1.393,1.304,1.411,1.099,1.203,1.373,1.142,1.241,1.44,1.277,1.431,1.021,1.036,1.123,1.129,1.094,1.086,1.122,1.446,1.031,1.066,1.035,1.028,1.067,1.038,1.083,0.989,1.084,1.118,1.141,1.145,1.004,1.182,1.037,1.051,1.094,1.167,1.121,1.131,0.963,1.185,1.036,1.052,1.037,1.079,1.129,1.055,1.174,1.128,1.081,1.036,1.137,1.127,1.061,1.071,1.111,1.192,1.103,1.132,1.121,1.079,1.224,1.128,1.189,1.054,1.206,1.261,1.15,1.237,1.081,1.13,1.132,1.269,1.208,1.107,1.094,1.219,1.218

learning_rate
0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005,0.0005

