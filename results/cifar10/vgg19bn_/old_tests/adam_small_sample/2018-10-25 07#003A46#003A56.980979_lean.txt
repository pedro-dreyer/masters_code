parameters
adam_beta1:0.9
adam_beta2:0.999
adam_eps:1e-08
adam_weight_decay:0.0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:0.1
initial_learning_rate:5e-06
executions:1
base_seed:1230
training_method:adam
learning_method:constant

train_loss
2.298,2.287,2.274,2.252,2.218,2.174,2.123,2.078,2.037,2.002,1.978,1.945,1.925,1.897,1.881,1.857,1.842,1.829,1.803,1.788,1.782,1.763,1.753,1.749,1.745,1.72,1.717,1.701,1.719,1.677,1.666,1.675,1.657,1.641,1.631,1.629,1.621,1.6,1.602,1.594,1.592,1.569,1.581,1.563,1.56,1.547,1.529,1.537,1.524,1.496,1.514,1.509,1.473,1.47,1.486,1.461,1.458,1.437,1.466,1.415,1.423,1.396,1.394,1.379,1.372,1.367,1.368,1.35,1.339,1.325,1.334,1.332,1.332,1.295,1.296,1.287,1.279,1.265,1.253,1.254,1.26,1.266,1.237,1.251,1.214,1.25,1.213,1.238,1.215,1.19,1.189,1.195,1.184,1.168,1.172,1.148,1.162,1.164,1.143,1.156

train_acc1
12.36,15.06,17.4,19.26,19.94,20.06,20.22,20.96,22.58,22.9,23.84,24.78,26.24,27.24,25.84,27.84,27.68,28.56,29.76,30.4,30.84,31.82,32.36,32.2,32.9,33.52,34.16,34.66,34.66,34.92,35.94,35.84,36.64,36.58,36.8,37.2,37.82,38.54,38.2,38.9,39.34,41.02,41.04,40.76,41.62,40.8,42.26,42.1,42.64,43.5,43.68,42.36,45.06,44.6,43.8,45.48,45.26,46.54,46.38,47.6,47.98,47.24,48.92,48.16,49.54,49.12,50.04,50.24,50.86,51.04,51.4,51.56,50.94,52.94,52.82,52.04,52.78,53.66,53.68,54.26,53.56,53.64,54.68,53.86,55.82,55.02,55.82,54.24,55.44,56.22,56.72,56.24,56.54,57.34,57.24,57.96,58.18,59.04,57.96,57.68

val_acc1
14.09,17.04,18.7,19.84,19.44,19.74,19.82,20.36,20.25,21.45,21.92,24.13,25.26,25.78,26.03,26.71,26.62,27.36,28.45,28.46,29.06,30.17,30.64,30.73,31.88,32.16,32.3,32.4,32.89,33.16,33.93,33.76,34.76,35.12,34.86,35.47,36.08,35.73,37.13,37.67,37.92,38.48,38.34,38.6,39.1,39.03,39.67,40.01,40.3,40.75,40.29,41.01,40.84,41.63,41.49,41.83,42.13,42.1,42.46,42.83,43.31,43.8,43.91,43.79,44.02,44.51,44.5,45.02,44.31,45.35,45.6,45.77,45.93,45.91,45.73,46.39,46.74,46.83,46.91,46.91,46.63,46.96,47.63,47.79,47.96,47.61,48.0,47.8,48.35,48.46,48.66,48.61,48.83,49.24,49.45,49.06,49.06,49.64,49.14,49.14

val_loss
2.298,2.284,2.266,2.241,2.192,2.138,2.087,2.039,1.988,1.969,1.933,1.922,1.896,1.874,1.859,1.845,1.839,1.827,1.799,1.789,1.781,1.76,1.75,1.751,1.729,1.728,1.72,1.717,1.699,1.703,1.679,1.689,1.679,1.668,1.664,1.65,1.651,1.645,1.63,1.624,1.619,1.611,1.622,1.613,1.601,1.589,1.583,1.583,1.574,1.568,1.577,1.556,1.562,1.543,1.539,1.53,1.52,1.522,1.515,1.515,1.507,1.489,1.488,1.487,1.481,1.47,1.464,1.457,1.467,1.449,1.439,1.445,1.446,1.443,1.44,1.431,1.42,1.415,1.412,1.408,1.416,1.398,1.393,1.402,1.395,1.387,1.382,1.39,1.378,1.38,1.371,1.377,1.372,1.369,1.367,1.365,1.363,1.358,1.377,1.365

learning_rate
5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06

