parameters
adam_lr:0.0003
adam_beta1:0.9
adam_beta2:0.99
adam_eps:1e-8
adam_weight_decay:0
adam_amsgrad:False
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:1
executions:2
base_seed:1230
training_method:adam
learning_method:constant

train_loss
1.568,1.063,0.839,0.72,0.64,0.568,0.516,0.469,0.437,0.408,0.382,0.355,0.332,0.306,0.29,0.276,0.259,0.243,0.228,0.217,0.203,0.197,0.182,0.175,0.166,0.158,0.149,0.142,0.136,0.13,0.121,0.117,0.114,0.105,0.105,0.1,0.096,0.09,0.089,0.087,0.084,0.079,0.079,0.076,0.073,0.07,0.07,0.068,0.064,0.062,0.064,0.058,0.058,0.057,0.056,0.051,0.052,0.051,0.049,0.05,0.047,0.047,0.046,0.046,0.046,0.042,0.042,0.039,0.043,0.037,0.04,0.04,0.036,0.037,0.037,0.038,0.036,0.034,0.034,0.032,0.034,0.032,0.033,0.032,0.031,0.03,0.028,0.031,0.03,0.031,0.028,0.027,0.027,0.028,0.026,0.028,0.026,0.025,0.026,0.026
1.55,1.054,0.842,0.727,0.646,0.577,0.528,0.484,0.448,0.419,0.385,0.36,0.34,0.312,0.295,0.283,0.262,0.246,0.232,0.225,0.209,0.199,0.187,0.176,0.166,0.161,0.155,0.145,0.139,0.132,0.127,0.123,0.117,0.113,0.11,0.102,0.098,0.096,0.091,0.088,0.089,0.085,0.081,0.077,0.074,0.074,0.067,0.072,0.071,0.066,0.062,0.064,0.06,0.057,0.058,0.056,0.051,0.054,0.051,0.049,0.048,0.048,0.048,0.047,0.045,0.047,0.043,0.046,0.042,0.04,0.043,0.036,0.038,0.038,0.037,0.037,0.039,0.034,0.034,0.036,0.033,0.033,0.031,0.032,0.032,0.033,0.03,0.03,0.031,0.03,0.03,0.028,0.028,0.027,0.03,0.029,0.025,0.027,0.025,0.025

train_acc1
39.048,62.238,70.66,75.652,78.098,80.814,82.492,84.174,85.286,86.214,87.048,87.962,88.8,89.632,90.222,90.604,91.218,91.728,92.242,92.816,93.018,93.304,93.858,93.99,94.268,94.654,94.8,95.102,95.312,95.6,95.818,95.97,96.114,96.412,96.34,96.66,96.784,96.954,97.004,96.932,97.082,97.314,97.302,97.36,97.504,97.636,97.68,97.664,97.794,97.874,97.834,98.05,98.064,98.046,98.068,98.3,98.228,98.234,98.332,98.32,98.378,98.512,98.488,98.422,98.428,98.59,98.56,98.636,98.556,98.696,98.61,98.692,98.776,98.72,98.698,98.746,98.794,98.836,98.822,98.92,98.83,98.92,98.934,98.914,98.974,98.976,99.038,98.958,99.014,98.94,99.036,99.036,99.042,99.062,99.11,99.052,99.126,99.204,99.174,99.112
40.106,61.88,70.528,74.92,77.982,80.55,82.22,83.728,84.89,85.764,87.186,87.932,88.45,89.358,90.11,90.432,91.118,91.726,92.146,92.32,92.872,93.394,93.622,94.03,94.352,94.612,94.736,95.044,95.278,95.552,95.744,95.774,96.13,96.206,96.272,96.526,96.65,96.79,96.894,97.026,97.012,97.122,97.124,97.318,97.402,97.474,97.686,97.606,97.566,97.75,97.972,97.788,97.916,98.018,98.01,98.148,98.268,98.148,98.218,98.298,98.344,98.354,98.38,98.418,98.484,98.38,98.542,98.442,98.594,98.612,98.576,98.72,98.718,98.754,98.75,98.738,98.746,98.878,98.88,98.788,98.904,98.968,98.946,98.962,98.946,98.896,98.926,99.034,99.034,99.026,99.006,99.002,99.084,99.092,99.006,99.08,99.126,99.106,99.2,99.168

val_acc1
55.48,69.52,71.85,76.4,74.75,77.93,81.12,81.7,82.64,82.69,84.85,85.02,85.03,86.1,86.53,86.73,86.62,86.63,87.34,86.34,85.93,87.31,88.21,87.35,88.58,87.43,88.58,87.73,87.79,88.29,88.68,88.38,89.24,88.66,89.19,88.75,89.34,89.17,88.77,89.14,89.44,88.72,89.32,89.86,89.7,90.22,89.91,89.12,89.79,89.69,90.26,89.27,89.53,89.34,89.79,89.75,89.4,90.16,90.38,90.32,90.01,90.22,89.59,89.95,90.41,90.14,90.49,90.38,89.98,89.81,90.32,89.88,90.06,90.63,90.46,90.5,90.23,90.54,89.93,90.35,90.29,90.35,89.95,90.75,90.51,90.74,90.54,90.89,90.02,90.17,90.33,90.04,90.54,90.65,90.86,90.58,89.86,90.12,90.43,90.95
53.83,64.87,68.72,75.7,77.53,79.46,78.11,79.07,81.67,83.93,82.5,84.74,85.65,86.23,85.44,85.31,85.95,86.43,87.77,86.29,86.92,87.75,87.33,87.52,87.97,88.19,88.73,88.98,86.51,88.44,88.66,89.21,88.8,88.62,88.95,89.86,88.86,88.5,88.75,89.55,89.19,89.02,89.64,88.95,89.19,89.7,89.55,89.83,89.9,89.39,90.12,90.32,89.43,89.38,90.18,89.33,89.93,89.79,89.65,90.12,90.06,89.95,90.65,90.17,89.81,90.42,90.44,89.41,90.16,90.27,90.65,89.99,90.19,90.51,90.35,90.21,90.26,90.44,90.52,90.74,90.28,90.66,90.58,90.51,90.46,90.45,91.06,90.67,90.19,90.39,90.52,90.23,90.81,90.44,90.92,91.03,90.97,90.83,90.33,91.04

val_loss
1.218,0.877,0.816,0.696,0.77,0.686,0.586,0.548,0.534,0.539,0.463,0.456,0.487,0.424,0.417,0.411,0.419,0.425,0.409,0.457,0.483,0.406,0.374,0.422,0.389,0.42,0.395,0.442,0.433,0.42,0.412,0.419,0.37,0.437,0.399,0.416,0.404,0.436,0.448,0.426,0.443,0.467,0.432,0.404,0.438,0.43,0.411,0.438,0.411,0.423,0.434,0.461,0.427,0.479,0.471,0.45,0.479,0.421,0.442,0.438,0.468,0.469,0.474,0.464,0.421,0.429,0.459,0.456,0.446,0.488,0.448,0.436,0.47,0.445,0.475,0.475,0.459,0.447,0.5,0.498,0.481,0.487,0.506,0.427,0.441,0.471,0.487,0.433,0.542,0.467,0.488,0.533,0.512,0.461,0.449,0.462,0.564,0.543,0.505,0.436
1.256,0.996,0.926,0.703,0.666,0.627,0.651,0.627,0.558,0.493,0.514,0.449,0.451,0.431,0.455,0.456,0.458,0.424,0.395,0.447,0.426,0.389,0.416,0.415,0.406,0.397,0.386,0.389,0.484,0.396,0.401,0.42,0.407,0.416,0.401,0.378,0.415,0.439,0.437,0.393,0.416,0.405,0.432,0.476,0.473,0.429,0.438,0.428,0.419,0.44,0.412,0.389,0.434,0.467,0.415,0.471,0.441,0.456,0.425,0.452,0.436,0.431,0.388,0.458,0.484,0.435,0.453,0.489,0.45,0.455,0.418,0.451,0.463,0.455,0.437,0.435,0.447,0.461,0.482,0.439,0.47,0.466,0.491,0.454,0.471,0.488,0.44,0.461,0.482,0.484,0.461,0.479,0.438,0.451,0.453,0.447,0.46,0.429,0.464,0.471

learning_rate
0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003
0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003

