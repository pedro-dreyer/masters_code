parameters
adam_lr:0.0003
adam_beta1:0.9
adam_beta2:0.99
adam_eps:1e-8
adam_weight_decay:0
adam_amsgrad:True
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:1
executions:2
base_seed:1230
training_method:adam
learning_method:constant

train_loss
1.573,1.071,0.833,0.708,0.625,0.557,0.503,0.459,0.431,0.4,0.37,0.347,0.325,0.299,0.28,0.267,0.254,0.235,0.218,0.21,0.188,0.188,0.176,0.163,0.157,0.146,0.144,0.128,0.126,0.118,0.112,0.11,0.099,0.095,0.098,0.087,0.085,0.078,0.077,0.075,0.068,0.068,0.067,0.064,0.059,0.055,0.058,0.054,0.052,0.047,0.05,0.049,0.044,0.041,0.04,0.041,0.04,0.038,0.036,0.037,0.033,0.033,0.034,0.028,0.033,0.029,0.027,0.027,0.03,0.025,0.026,0.025,0.026,0.026,0.022,0.022,0.025,0.024,0.02,0.02,0.021,0.02,0.022,0.021,0.02,0.018,0.017,0.02,0.018,0.014,0.02,0.016,0.015,0.016,0.013,0.015,0.014,0.017,0.016,0.014
1.552,1.059,0.837,0.717,0.64,0.569,0.523,0.475,0.442,0.409,0.381,0.356,0.331,0.304,0.293,0.275,0.255,0.244,0.226,0.217,0.203,0.189,0.182,0.167,0.162,0.155,0.15,0.134,0.131,0.122,0.115,0.113,0.106,0.102,0.099,0.092,0.086,0.081,0.081,0.075,0.075,0.067,0.069,0.069,0.062,0.056,0.058,0.059,0.055,0.054,0.052,0.05,0.045,0.043,0.046,0.041,0.042,0.038,0.038,0.037,0.033,0.033,0.035,0.032,0.032,0.028,0.03,0.028,0.029,0.028,0.028,0.025,0.023,0.024,0.023,0.023,0.024,0.021,0.022,0.021,0.023,0.022,0.02,0.022,0.02,0.02,0.021,0.016,0.019,0.017,0.016,0.017,0.019,0.015,0.017,0.018,0.014,0.014,0.013,0.013

train_acc1
38.796,61.846,70.958,75.804,78.662,81.172,82.946,84.456,85.282,86.474,87.586,88.296,88.94,90.034,90.52,90.978,91.35,92.138,92.642,92.99,93.488,93.522,94.062,94.42,94.54,94.908,95.074,95.574,95.644,95.944,96.194,96.226,96.554,96.744,96.692,97.114,97.01,97.29,97.326,97.392,97.66,97.614,97.724,97.772,97.966,98.106,98.012,98.126,98.196,98.432,98.276,98.368,98.508,98.552,98.66,98.656,98.63,98.736,98.788,98.788,98.88,98.832,98.826,99.012,98.87,99.0,99.072,99.036,98.962,99.13,99.106,99.122,99.128,99.138,99.262,99.212,99.136,99.154,99.292,99.342,99.266,99.27,99.208,99.292,99.294,99.422,99.426,99.29,99.404,99.558,99.388,99.494,99.452,99.454,99.568,99.476,99.518,99.408,99.44,99.532
40.144,62.028,70.624,75.152,78.106,80.896,82.25,83.864,85.18,86.298,87.066,87.94,88.752,89.714,90.064,90.668,91.394,91.686,92.36,92.648,93.048,93.586,93.806,94.288,94.474,94.694,94.884,95.418,95.532,95.856,96.014,96.158,96.32,96.514,96.68,96.872,97.046,97.13,97.16,97.452,97.452,97.694,97.626,97.662,97.866,98.106,97.992,98.022,98.158,98.192,98.228,98.368,98.458,98.52,98.384,98.638,98.542,98.716,98.708,98.73,98.862,98.862,98.786,98.92,98.954,99.03,99.004,99.05,99.078,99.1,99.108,99.138,99.214,99.2,99.184,99.212,99.192,99.288,99.232,99.268,99.206,99.268,99.314,99.228,99.328,99.312,99.278,99.432,99.338,99.414,99.454,99.372,99.352,99.472,99.364,99.408,99.538,99.53,99.562,99.544

val_acc1
51.31,68.52,73.51,76.44,77.46,78.13,81.33,81.74,82.87,83.52,84.08,84.81,85.18,86.55,85.24,85.97,86.5,86.92,87.54,86.85,86.54,87.73,88.37,87.68,87.48,88.17,88.54,86.5,87.17,88.44,88.66,89.03,88.91,89.22,89.1,88.82,89.15,89.49,88.79,89.35,89.13,89.74,89.4,89.61,89.23,89.61,89.48,89.2,89.67,89.53,89.53,89.98,89.82,89.56,89.22,89.36,89.53,90.0,89.82,90.23,89.14,90.06,89.68,89.75,89.23,90.22,90.16,89.81,89.82,89.83,89.82,90.19,90.29,90.11,90.31,90.56,90.12,90.2,90.38,90.23,89.59,89.96,90.29,90.74,90.43,90.55,90.28,90.09,90.33,90.61,90.75,90.65,90.69,90.16,90.79,90.68,90.61,90.7,90.48,90.4
54.48,66.1,69.06,75.47,76.82,79.19,80.22,81.96,83.39,83.5,83.79,84.8,84.54,85.91,85.98,85.84,86.39,87.21,87.54,86.69,87.22,87.43,87.29,87.3,87.31,88.53,88.16,88.12,87.95,88.15,88.47,88.69,88.46,88.45,88.42,89.1,88.75,88.65,89.09,89.18,88.68,89.46,89.19,89.15,89.78,89.66,89.86,89.37,89.91,89.38,89.75,89.93,89.84,89.92,89.77,89.78,89.97,89.82,89.86,90.48,89.85,89.84,89.85,90.01,89.37,90.23,90.62,89.87,90.2,90.05,89.72,90.33,90.26,90.21,90.33,89.21,90.01,90.67,90.17,89.87,90.35,90.45,90.06,90.07,89.71,90.6,90.57,90.68,90.35,90.42,90.89,90.03,90.82,89.82,91.0,90.15,90.41,90.39,90.35,90.68

val_loss
1.363,0.909,0.772,0.693,0.676,0.652,0.561,0.551,0.539,0.522,0.478,0.465,0.474,0.409,0.453,0.433,0.435,0.406,0.412,0.43,0.428,0.397,0.392,0.41,0.438,0.396,0.384,0.487,0.473,0.391,0.404,0.398,0.406,0.411,0.413,0.42,0.408,0.397,0.443,0.405,0.436,0.42,0.407,0.418,0.442,0.447,0.434,0.46,0.434,0.443,0.463,0.417,0.44,0.461,0.496,0.461,0.464,0.457,0.478,0.451,0.489,0.439,0.447,0.459,0.485,0.461,0.469,0.482,0.47,0.481,0.46,0.467,0.47,0.458,0.455,0.451,0.467,0.465,0.462,0.467,0.522,0.487,0.462,0.436,0.464,0.474,0.493,0.491,0.469,0.487,0.468,0.468,0.489,0.477,0.466,0.473,0.48,0.474,0.482,0.477
1.235,0.963,0.932,0.719,0.7,0.632,0.598,0.542,0.502,0.515,0.482,0.454,0.483,0.444,0.436,0.432,0.43,0.406,0.398,0.427,0.408,0.402,0.419,0.429,0.416,0.374,0.397,0.395,0.418,0.414,0.397,0.397,0.418,0.411,0.42,0.4,0.422,0.422,0.411,0.406,0.433,0.404,0.443,0.422,0.407,0.422,0.397,0.43,0.413,0.434,0.414,0.411,0.433,0.422,0.43,0.444,0.417,0.444,0.434,0.41,0.445,0.441,0.439,0.444,0.456,0.434,0.437,0.45,0.445,0.462,0.501,0.453,0.429,0.45,0.442,0.5,0.466,0.471,0.461,0.486,0.452,0.448,0.476,0.48,0.484,0.475,0.446,0.464,0.468,0.465,0.461,0.473,0.458,0.504,0.436,0.457,0.453,0.459,0.467,0.452

learning_rate
0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003
0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003,0.0003

