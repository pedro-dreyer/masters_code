parameters
tas_alpha:50
tas_beta:0.7
tas_gamma:0.02
sgd_lr:0.05
sgd_momentum:0.9
sgd_weight_decay:0
sgd_dampening:0
sgd_nesterov:True
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:50
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:1
executions:2
base_seed:1230
training_method:sgd
learning_method:tas

train_loss
2.238,1.717,1.421,1.139,0.931,0.772,0.671,0.599,0.541,0.493,0.453,0.422,0.387,0.359,0.335,0.319,0.289,0.277,0.256,0.243,0.225,0.214,0.2,0.186,0.18,0.166,0.16,0.15,0.137,0.131,0.127,0.118,0.111,0.094,0.077,0.056,0.037,0.026,0.023,0.02,0.019,0.018,0.017,0.018,0.017,0.017,0.017,0.017,0.016,0.016
2.328,1.824,1.561,1.259,1.001,0.833,0.728,0.642,0.582,0.527,0.481,0.442,0.41,0.378,0.351,0.334,0.308,0.287,0.271,0.252,0.236,0.225,0.208,0.199,0.185,0.172,0.17,0.156,0.147,0.136,0.13,0.125,0.115,0.101,0.083,0.059,0.039,0.029,0.024,0.022,0.021,0.019,0.019,0.019,0.019,0.017,0.018,0.017,0.018,0.016

train_acc1
18.518,34.134,47.46,59.312,67.262,73.382,77.088,79.546,81.746,83.448,84.806,85.8,86.872,87.894,88.612,89.256,90.294,90.528,91.252,91.728,92.33,92.678,93.088,93.556,93.77,94.298,94.542,94.786,95.33,95.55,95.664,95.882,96.168,96.696,97.326,98.07,98.764,99.116,99.246,99.352,99.396,99.432,99.436,99.424,99.454,99.456,99.456,99.48,99.464,99.464
14.376,28.48,40.566,54.168,64.698,71.228,75.06,78.102,80.422,82.376,83.674,85.098,86.08,87.372,88.152,88.824,89.468,90.324,90.754,91.316,91.928,92.28,92.88,93.132,93.728,94.14,94.092,94.778,94.938,95.316,95.536,95.61,96.066,96.514,97.142,97.984,98.68,99.026,99.22,99.284,99.32,99.348,99.372,99.402,99.362,99.442,99.412,99.462,99.41,99.45

val_acc1
29.52,40.9,50.77,61.15,70.63,72.64,76.84,76.97,81.22,80.9,82.33,84.04,82.62,83.79,85.48,85.03,85.4,87.39,86.74,87.78,85.8,86.89,87.73,87.67,88.27,87.68,87.85,87.25,89.13,88.41,88.82,87.98,88.17,89.99,90.05,90.68,91.2,91.25,91.45,91.14,91.24,91.3,91.33,91.27,91.25,91.29,91.43,91.39,91.39,91.33
22.23,35.54,46.59,57.08,67.77,72.11,75.54,77.83,80.34,77.98,81.92,83.07,82.74,85.53,84.15,85.96,82.49,86.38,86.63,85.85,86.53,87.14,87.1,86.92,87.45,88.22,87.5,87.38,88.05,87.83,88.33,88.94,88.25,89.65,89.61,90.3,90.5,90.76,91.02,90.89,91.01,91.02,90.97,91.09,91.08,91.1,90.98,90.98,91.12,90.93

val_loss
1.807,1.53,1.377,1.094,0.835,0.79,0.693,0.664,0.573,0.584,0.535,0.459,0.539,0.506,0.432,0.463,0.452,0.373,0.422,0.383,0.46,0.424,0.389,0.403,0.375,0.398,0.404,0.434,0.372,0.379,0.38,0.451,0.419,0.364,0.386,0.373,0.379,0.401,0.393,0.395,0.401,0.397,0.412,0.403,0.421,0.425,0.411,0.413,0.417,0.42
2.072,1.679,1.416,1.367,0.922,0.817,0.72,0.67,0.597,0.674,0.553,0.494,0.521,0.448,0.474,0.423,0.558,0.406,0.418,0.438,0.437,0.409,0.409,0.422,0.395,0.368,0.418,0.44,0.408,0.407,0.388,0.412,0.424,0.373,0.387,0.38,0.397,0.406,0.399,0.399,0.408,0.404,0.405,0.412,0.416,0.426,0.416,0.415,0.415,0.422

learning_rate
0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.049999,0.049998,0.049994,0.049984,0.049955,0.049879,0.049672,0.049119,0.047676,0.044159,0.036822,0.0255,0.014178,0.006841,0.003324,0.001881,0.001328,0.001121,0.001045,0.001016,0.001006,0.001002,0.001001,0.001,0.001,0.001
0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.049999,0.049998,0.049994,0.049984,0.049955,0.049879,0.049672,0.049119,0.047676,0.044159,0.036822,0.0255,0.014178,0.006841,0.003324,0.001881,0.001328,0.001121,0.001045,0.001016,0.001006,0.001002,0.001001,0.001,0.001,0.001

