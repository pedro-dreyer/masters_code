parameters
tas_alpha:25
tas_beta:0.3
tas_gamma:0.02
sgd_lr:0.05
sgd_momentum:0.9
sgd_weight_decay:0
sgd_dampening:0
sgd_nesterov:True
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:50
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:1
executions:2
base_seed:1230
training_method:sgd
learning_method:tas

train_loss
2.27,1.821,1.496,1.214,0.993,0.821,0.704,0.619,0.563,0.509,0.465,0.427,0.387,0.349,0.311,0.283,0.243,0.213,0.186,0.166,0.151,0.14,0.134,0.128,0.123,0.12,0.12,0.115,0.111,0.11,0.109,0.109,0.106,0.105,0.105,0.105,0.103,0.098,0.101,0.099,0.097,0.096,0.094,0.095,0.091,0.088,0.088,0.089,0.087,0.085
2.403,1.871,1.539,1.256,1.032,0.856,0.729,0.641,0.581,0.524,0.478,0.443,0.4,0.363,0.323,0.293,0.255,0.225,0.196,0.177,0.162,0.151,0.145,0.138,0.133,0.128,0.128,0.126,0.122,0.12,0.12,0.118,0.114,0.115,0.111,0.114,0.11,0.108,0.11,0.109,0.107,0.105,0.104,0.103,0.1,0.097,0.099,0.095,0.093,0.094

train_acc1
17.316,29.39,44.072,56.594,65.104,71.902,76.04,78.704,80.848,82.66,84.192,85.66,86.82,88.19,89.406,90.412,91.682,92.75,93.546,94.374,94.836,95.192,95.514,95.626,95.81,95.856,95.872,96.034,96.212,96.268,96.274,96.154,96.332,96.378,96.338,96.306,96.428,96.638,96.562,96.526,96.714,96.674,96.748,96.688,96.928,96.884,96.89,96.966,96.992,97.028
13.586,27.448,42.008,54.36,63.214,70.2,74.956,78.238,80.456,82.276,83.766,84.848,86.524,87.728,89.044,89.998,91.152,92.32,93.274,93.954,94.542,94.78,95.002,95.346,95.352,95.648,95.652,95.696,95.854,95.87,95.84,95.938,96.022,96.064,96.188,96.002,96.16,96.312,96.222,96.23,96.402,96.408,96.434,96.432,96.542,96.698,96.566,96.678,96.838,96.774

val_acc1
25.48,34.92,48.86,58.76,68.84,72.58,76.85,78.02,79.65,81.14,80.81,82.82,84.07,84.3,86.56,87.16,87.83,88.42,89.02,89.21,89.36,89.32,89.22,89.4,89.35,89.52,89.34,89.47,89.57,89.51,89.42,89.54,89.5,89.51,89.6,89.37,89.55,89.51,89.49,89.49,89.26,89.34,89.61,89.43,89.34,89.47,89.42,89.43,89.37,89.5
22.36,34.51,47.3,57.9,65.09,70.5,73.35,79.58,79.93,80.95,81.93,82.14,83.89,85.95,84.73,86.8,87.14,88.24,89.02,89.05,89.34,89.21,89.17,89.36,89.4,89.54,89.46,89.4,89.45,89.47,89.27,89.49,89.48,89.52,89.48,89.46,89.46,89.65,89.62,89.32,89.57,89.5,89.39,89.51,89.36,89.48,89.57,89.44,89.52,89.41

val_loss
1.957,1.886,1.463,1.207,0.877,0.819,0.678,0.647,0.617,0.571,0.574,0.507,0.481,0.481,0.413,0.379,0.378,0.363,0.362,0.356,0.345,0.351,0.358,0.365,0.365,0.359,0.37,0.369,0.369,0.369,0.373,0.374,0.376,0.381,0.385,0.378,0.382,0.393,0.383,0.386,0.388,0.391,0.402,0.393,0.403,0.421,0.401,0.398,0.413,0.402
1.961,1.718,1.419,1.233,1.018,0.851,0.812,0.595,0.607,0.574,0.536,0.528,0.487,0.432,0.449,0.399,0.386,0.365,0.351,0.346,0.342,0.344,0.346,0.356,0.359,0.352,0.358,0.358,0.36,0.356,0.36,0.368,0.365,0.369,0.377,0.368,0.369,0.372,0.371,0.374,0.376,0.369,0.386,0.375,0.391,0.394,0.378,0.388,0.391,0.393

learning_rate
0.049973,0.049955,0.049926,0.049879,0.049801,0.049672,0.049462,0.049119,0.048564,0.047676,0.046283,0.044159,0.041061,0.036822,0.031501,0.0255,0.019499,0.014178,0.009939,0.006841,0.004717,0.003324,0.002436,0.001881,0.001538,0.001328,0.001199,0.001121,0.001074,0.001045,0.001027,0.001016,0.00101,0.001006,0.001004,0.001002,0.001001,0.001001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
0.049973,0.049955,0.049926,0.049879,0.049801,0.049672,0.049462,0.049119,0.048564,0.047676,0.046283,0.044159,0.041061,0.036822,0.031501,0.0255,0.019499,0.014178,0.009939,0.006841,0.004717,0.003324,0.002436,0.001881,0.001538,0.001328,0.001199,0.001121,0.001074,0.001045,0.001027,0.001016,0.00101,0.001006,0.001004,0.001002,0.001001,0.001001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001

