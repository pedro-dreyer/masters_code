parameters
tas_alpha:25
tas_beta:0.5
tas_gamma:0.02
sgd_lr:0.05
sgd_momentum:0.9
sgd_weight_decay:0
sgd_dampening:0
sgd_nesterov:True
architecture:vgg19bn_
dataset:cifar10
combine_datasets:False
do_validation_set:False
epochs:50
batch_size:128
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:1
executions:2
base_seed:1230
training_method:sgd
learning_method:tas

train_loss
2.225,1.736,1.436,1.154,0.953,0.794,0.685,0.602,0.543,0.492,0.452,0.419,0.386,0.353,0.33,0.318,0.29,0.267,0.255,0.236,0.217,0.202,0.182,0.165,0.139,0.12,0.098,0.079,0.063,0.052,0.05,0.045,0.04,0.038,0.036,0.034,0.036,0.033,0.033,0.033,0.032,0.032,0.03,0.03,0.03,0.029,0.028,0.029,0.029,0.028
2.397,1.869,1.549,1.258,1.002,0.816,0.712,0.628,0.57,0.515,0.469,0.434,0.402,0.367,0.339,0.324,0.297,0.278,0.256,0.241,0.219,0.204,0.182,0.163,0.139,0.117,0.096,0.076,0.062,0.05,0.045,0.043,0.038,0.036,0.035,0.033,0.032,0.03,0.032,0.03,0.029,0.029,0.029,0.03,0.028,0.028,0.028,0.027,0.027,0.026

train_acc1
18.494,33.58,46.806,58.804,66.662,72.586,76.696,79.416,81.49,83.534,84.568,85.75,86.89,88.112,88.9,89.166,90.054,90.946,91.288,91.922,92.502,93.082,93.874,94.31,95.292,95.782,96.662,97.312,97.878,98.212,98.296,98.532,98.692,98.772,98.786,98.85,98.718,98.866,98.94,98.866,98.916,98.938,99.002,99.006,99.026,99.002,99.038,99.002,99.024,99.054
12.376,27.36,41.256,54.668,64.696,71.602,75.462,78.56,80.66,82.634,84.212,85.386,86.462,87.602,88.714,88.97,89.926,90.624,91.32,91.754,92.484,93.08,93.794,94.436,95.282,95.998,96.714,97.352,97.892,98.364,98.466,98.536,98.7,98.794,98.848,98.83,98.924,99.028,98.916,99.0,99.034,98.994,99.028,99.008,99.024,99.04,99.042,99.058,99.088,99.114

val_acc1
26.59,40.91,51.67,56.86,69.69,72.53,74.72,80.66,81.67,79.32,84.02,84.1,82.51,84.54,84.58,86.75,84.57,86.83,87.33,86.87,87.35,85.91,88.51,88.16,89.23,89.44,89.32,90.03,90.27,90.62,90.56,90.85,90.76,90.88,90.97,91.01,90.72,90.92,90.93,90.85,90.69,90.8,90.61,90.6,90.78,90.79,90.86,90.8,90.6,90.83
20.89,34.83,43.88,53.24,68.52,70.95,77.53,77.69,78.79,81.52,82.78,83.05,83.35,85.62,85.34,83.28,85.27,85.6,87.14,86.39,84.9,86.72,88.7,88.26,88.63,89.39,89.82,90.17,90.38,90.53,90.72,90.76,90.94,90.77,90.82,90.85,90.62,90.72,90.8,90.75,90.73,90.74,90.57,90.67,90.82,90.86,90.91,90.78,90.74,90.82

val_loss
1.908,1.564,1.344,1.288,0.862,0.83,0.76,0.579,0.55,0.636,0.468,0.46,0.561,0.483,0.456,0.396,0.475,0.403,0.383,0.427,0.399,0.456,0.371,0.38,0.354,0.357,0.385,0.357,0.374,0.371,0.372,0.375,0.379,0.381,0.394,0.389,0.394,0.404,0.395,0.399,0.409,0.408,0.409,0.415,0.418,0.436,0.422,0.417,0.435,0.417
2.321,1.717,1.59,1.293,0.88,0.847,0.657,0.663,0.636,0.561,0.52,0.492,0.502,0.437,0.45,0.512,0.45,0.439,0.391,0.436,0.488,0.447,0.368,0.395,0.38,0.377,0.381,0.379,0.382,0.389,0.387,0.389,0.394,0.398,0.412,0.403,0.414,0.416,0.417,0.41,0.427,0.415,0.43,0.415,0.437,0.439,0.428,0.426,0.43,0.426

learning_rate
0.05,0.05,0.05,0.049999,0.049999,0.049998,0.049996,0.049994,0.04999,0.049984,0.049973,0.049955,0.049926,0.049879,0.049801,0.049672,0.049462,0.049119,0.048564,0.047676,0.046283,0.044159,0.041061,0.036822,0.031501,0.0255,0.019499,0.014178,0.009939,0.006841,0.004717,0.003324,0.002436,0.001881,0.001538,0.001328,0.001199,0.001121,0.001074,0.001045,0.001027,0.001016,0.00101,0.001006,0.001004,0.001002,0.001001,0.001001,0.001,0.001
0.05,0.05,0.05,0.049999,0.049999,0.049998,0.049996,0.049994,0.04999,0.049984,0.049973,0.049955,0.049926,0.049879,0.049801,0.049672,0.049462,0.049119,0.048564,0.047676,0.046283,0.044159,0.041061,0.036822,0.031501,0.0255,0.019499,0.014178,0.009939,0.006841,0.004717,0.003324,0.002436,0.001881,0.001538,0.001328,0.001199,0.001121,0.001074,0.001045,0.001027,0.001016,0.00101,0.001006,0.001004,0.001002,0.001001,0.001001,0.001,0.001

