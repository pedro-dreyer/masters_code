parameters
tas_alpha:25
tas_beta:0.7
tas_gamma:0.02
sgd_lr:0.05
sgd_momentum:0.9
sgd_weight_decay:0
sgd_dampening:0
sgd_nesterov:False
architecture:lenet5
dataset:mnist
combine_datasets:False
do_validation_set:False
epochs:100
batch_size:1024
test_set_split:0.1666667
validation_set_split:0.0
reduce_train_set:1
executions:3
base_seed:42
training_method:sgd
learning_method:tas

train_loss
1.468,0.152,0.076,0.06,0.05,0.042,0.039,0.034,0.032,0.028,0.026,0.023,0.021,0.02,0.019,0.017,0.016,0.016,0.015,0.013,0.012,0.011,0.01,0.009,0.009,0.008,0.008,0.007,0.006,0.006,0.005,0.005,0.005,0.004,0.004,0.003,0.003,0.003,0.003,0.003,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.0,0.001,0.001,0.001,0.001,0.001
1.461,0.158,0.086,0.065,0.054,0.047,0.041,0.037,0.034,0.031,0.028,0.025,0.024,0.022,0.02,0.02,0.018,0.017,0.016,0.015,0.013,0.012,0.012,0.01,0.01,0.009,0.009,0.008,0.008,0.007,0.007,0.006,0.005,0.005,0.005,0.004,0.004,0.004,0.004,0.003,0.003,0.003,0.003,0.002,0.003,0.003,0.002,0.002,0.002,0.002,0.002,0.002,0.002,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
1.446,0.153,0.083,0.064,0.053,0.046,0.039,0.034,0.032,0.029,0.026,0.025,0.023,0.02,0.02,0.018,0.017,0.015,0.015,0.014,0.012,0.011,0.011,0.01,0.01,0.009,0.009,0.008,0.007,0.007,0.006,0.006,0.006,0.005,0.005,0.005,0.004,0.004,0.004,0.003,0.003,0.003,0.003,0.003,0.003,0.002,0.002,0.002,0.002,0.002,0.001,0.002,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001

train_acc1
49.922,95.45,97.665,98.137,98.475,98.72,98.828,98.977,99.033,99.155,99.148,99.257,99.362,99.39,99.473,99.492,99.542,99.562,99.582,99.65,99.673,99.705,99.715,99.783,99.79,99.835,99.832,99.835,99.872,99.888,99.91,99.905,99.925,99.952,99.948,99.97,99.968,99.978,99.977,99.985,99.983,99.985,99.988,99.993,99.988,99.993,99.997,99.995,99.992,99.997,99.995,99.998,99.998,99.998,99.998,100.0,100.0,99.998,100.0,100.0,100.0,100.0,100.0,100.0,99.998,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
48.978,95.19,97.432,98.0,98.3,98.608,98.743,98.875,98.962,99.048,99.142,99.245,99.247,99.333,99.4,99.405,99.517,99.498,99.505,99.545,99.637,99.682,99.692,99.723,99.738,99.775,99.802,99.775,99.803,99.842,99.838,99.883,99.913,99.892,99.89,99.947,99.952,99.94,99.945,99.958,99.962,99.982,99.982,99.973,99.952,99.975,99.985,99.99,99.99,99.993,99.99,99.99,99.992,99.995,99.997,99.993,99.997,99.995,99.993,99.998,99.997,99.995,100.0,99.998,99.998,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
49.958,95.275,97.498,98.048,98.418,98.578,98.788,98.938,99.032,99.148,99.21,99.262,99.267,99.43,99.405,99.513,99.49,99.602,99.588,99.612,99.695,99.733,99.702,99.725,99.755,99.782,99.785,99.795,99.828,99.822,99.862,99.87,99.863,99.895,99.907,99.913,99.93,99.93,99.942,99.953,99.943,99.968,99.97,99.972,99.937,99.978,99.985,99.988,99.99,99.99,99.995,99.99,99.992,99.995,99.998,99.995,99.998,99.997,99.997,99.998,100.0,99.998,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0

val_acc1
92.72,97.64,98.09,98.27,98.42,98.62,98.74,98.75,98.72,98.66,98.76,98.76,98.9,98.84,98.73,98.85,98.83,98.88,99.01,98.91,98.88,98.84,98.94,98.73,98.96,98.99,98.97,98.85,98.89,98.94,98.94,98.9,99.0,98.83,98.88,98.94,98.97,98.88,98.96,98.98,98.99,98.96,98.97,98.92,98.95,98.91,98.99,99.02,98.96,98.97,98.98,98.97,98.97,99.0,99.02,99.0,98.96,98.98,99.04,98.99,98.98,98.94,99.01,98.98,98.95,99.01,98.98,98.94,99.04,98.99,98.97,98.97,98.98,99.01,98.99,99.01,98.99,99.0,98.96,98.97,98.98,98.97,98.96,98.98,98.97,98.97,98.97,98.97,98.97,99.0,98.97,98.98,98.98,98.98,98.96,98.97,99.0,98.98,98.98,98.96
92.13,97.08,97.59,98.27,98.46,98.62,98.76,98.85,98.66,98.77,98.96,98.99,98.92,98.96,98.97,98.63,98.93,99.0,98.94,98.99,99.0,98.8,99.04,98.97,99.01,99.09,99.01,99.05,99.01,99.03,98.94,99.0,99.01,99.08,99.01,99.08,99.08,99.05,99.09,99.0,99.13,99.06,99.12,99.13,99.15,99.02,99.12,99.15,99.04,99.11,99.08,99.11,99.1,99.08,99.06,99.11,99.12,99.09,99.12,99.07,99.1,99.11,99.06,99.06,99.12,99.11,99.09,99.16,99.1,99.08,99.1,99.07,99.08,99.1,99.08,99.09,99.11,99.07,99.1,99.09,99.1,99.1,99.09,99.1,99.1,99.1,99.1,99.1,99.1,99.07,99.1,99.1,99.1,99.1,99.1,99.1,99.1,99.1,99.1,99.1
91.83,97.34,97.95,98.17,98.53,98.81,98.9,99.01,99.0,98.94,98.99,98.99,99.03,99.03,99.11,99.04,99.07,99.03,99.14,99.03,99.09,98.98,99.09,99.07,99.09,99.15,99.0,99.06,99.03,99.14,99.05,99.09,99.03,99.07,99.05,99.07,99.09,99.15,99.14,98.95,99.06,99.06,99.1,99.12,99.05,99.11,99.12,99.08,99.08,99.04,99.12,99.03,99.15,99.13,99.08,99.06,99.11,99.07,99.12,99.11,99.13,99.11,99.08,99.07,99.12,99.13,99.09,99.11,99.13,99.1,99.13,99.12,99.1,99.1,99.1,99.13,99.11,99.12,99.11,99.12,99.12,99.12,99.14,99.11,99.12,99.13,99.11,99.12,99.12,99.12,99.11,99.11,99.12,99.12,99.13,99.12,99.12,99.12,99.12,99.12

val_loss
0.254,0.081,0.062,0.052,0.051,0.041,0.037,0.04,0.041,0.041,0.038,0.037,0.034,0.035,0.038,0.035,0.033,0.036,0.032,0.035,0.035,0.037,0.033,0.039,0.034,0.036,0.037,0.037,0.038,0.037,0.036,0.038,0.037,0.038,0.038,0.037,0.038,0.041,0.038,0.039,0.042,0.042,0.04,0.04,0.041,0.043,0.042,0.042,0.043,0.042,0.043,0.044,0.043,0.044,0.043,0.044,0.044,0.044,0.044,0.044,0.045,0.045,0.046,0.046,0.045,0.045,0.045,0.045,0.046,0.046,0.046,0.045,0.046,0.046,0.046,0.046,0.045,0.047,0.046,0.046,0.046,0.046,0.045,0.047,0.046,0.046,0.046,0.046,0.046,0.046,0.046,0.046,0.046,0.046,0.046,0.046,0.047,0.046,0.046,0.047
0.285,0.096,0.076,0.052,0.048,0.043,0.038,0.037,0.04,0.036,0.032,0.032,0.033,0.031,0.031,0.04,0.032,0.031,0.032,0.032,0.034,0.036,0.03,0.03,0.03,0.03,0.03,0.03,0.031,0.03,0.033,0.032,0.033,0.032,0.032,0.03,0.031,0.032,0.032,0.033,0.032,0.034,0.032,0.032,0.032,0.035,0.032,0.032,0.034,0.033,0.034,0.033,0.033,0.034,0.034,0.035,0.035,0.034,0.035,0.035,0.035,0.034,0.036,0.037,0.036,0.035,0.036,0.035,0.037,0.036,0.036,0.036,0.037,0.036,0.036,0.037,0.036,0.037,0.037,0.036,0.037,0.037,0.036,0.037,0.037,0.036,0.037,0.036,0.036,0.037,0.036,0.037,0.036,0.037,0.037,0.036,0.037,0.036,0.036,0.037
0.264,0.088,0.068,0.054,0.047,0.04,0.035,0.032,0.032,0.034,0.03,0.032,0.032,0.03,0.028,0.029,0.029,0.028,0.027,0.029,0.028,0.035,0.027,0.027,0.028,0.027,0.03,0.03,0.031,0.03,0.033,0.033,0.029,0.029,0.031,0.03,0.029,0.032,0.029,0.033,0.03,0.032,0.032,0.031,0.034,0.03,0.031,0.032,0.035,0.033,0.033,0.033,0.032,0.033,0.033,0.034,0.034,0.034,0.033,0.033,0.034,0.034,0.035,0.036,0.035,0.035,0.035,0.035,0.035,0.036,0.035,0.035,0.035,0.035,0.036,0.036,0.035,0.036,0.036,0.036,0.035,0.036,0.036,0.036,0.036,0.035,0.036,0.036,0.035,0.035,0.035,0.036,0.035,0.037,0.036,0.035,0.036,0.035,0.035,0.036

learning_rate
0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.049999,0.049999,0.049999,0.049999,0.049998,0.049998,0.049997,0.049996,0.049995,0.049994,0.049992,0.04999,0.049987,0.049984,0.049979,0.049973,0.049965,0.049955,0.049943,0.049926,0.049906,0.049879,0.049845,0.049801,0.049744,0.049672,0.04958,0.049462,0.049311,0.049119,0.048874,0.048564,0.048171,0.047676,0.047056,0.046283,0.045328,0.044159,0.042746,0.041061,0.039088,0.036822,0.03428,0.031501,0.028547,0.0255,0.022453,0.019499,0.01672,0.014178,0.011912,0.009939,0.008254,0.006841,0.005672,0.004717,0.003944,0.003324,0.002829,0.002436,0.002126,0.001881,0.001689,0.001538,0.00142,0.001328,0.001256,0.001199,0.001155,0.001121,0.001094,0.001074,0.001057,0.001045,0.001035,0.001027
0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.049999,0.049999,0.049999,0.049999,0.049998,0.049998,0.049997,0.049996,0.049995,0.049994,0.049992,0.04999,0.049987,0.049984,0.049979,0.049973,0.049965,0.049955,0.049943,0.049926,0.049906,0.049879,0.049845,0.049801,0.049744,0.049672,0.04958,0.049462,0.049311,0.049119,0.048874,0.048564,0.048171,0.047676,0.047056,0.046283,0.045328,0.044159,0.042746,0.041061,0.039088,0.036822,0.03428,0.031501,0.028547,0.0255,0.022453,0.019499,0.01672,0.014178,0.011912,0.009939,0.008254,0.006841,0.005672,0.004717,0.003944,0.003324,0.002829,0.002436,0.002126,0.001881,0.001689,0.001538,0.00142,0.001328,0.001256,0.001199,0.001155,0.001121,0.001094,0.001074,0.001057,0.001045,0.001035,0.001027
0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.049999,0.049999,0.049999,0.049999,0.049998,0.049998,0.049997,0.049996,0.049995,0.049994,0.049992,0.04999,0.049987,0.049984,0.049979,0.049973,0.049965,0.049955,0.049943,0.049926,0.049906,0.049879,0.049845,0.049801,0.049744,0.049672,0.04958,0.049462,0.049311,0.049119,0.048874,0.048564,0.048171,0.047676,0.047056,0.046283,0.045328,0.044159,0.042746,0.041061,0.039088,0.036822,0.03428,0.031501,0.028547,0.0255,0.022453,0.019499,0.01672,0.014178,0.011912,0.009939,0.008254,0.006841,0.005672,0.004717,0.003944,0.003324,0.002829,0.002436,0.002126,0.001881,0.001689,0.001538,0.00142,0.001328,0.001256,0.001199,0.001155,0.001121,0.001094,0.001074,0.001057,0.001045,0.001035,0.001027

