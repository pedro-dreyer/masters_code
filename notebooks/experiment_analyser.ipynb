{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from misc.experiment_loader import *\n",
    "\n",
    "folder_path = '../results/cifar10/vgg19bn_/first_experiment/data/'\n",
    "full_experiment = FullExperiment(folder_path=folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# SGD experiments\n",
    "\n",
    "sgd_experiments = full_experiment.filter_parameters({'training_method': 'sgd',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(sgd_experiments.len)\n",
    "\n",
    "\n",
    "# we have 25 experiments in total, 7 for sgd without moment 7 for sgd with moment \n",
    "# 7 for sgd with nesterov moment and more 5 (4 new and 1 already presented among the \n",
    "# 7 from the sgd with nesterov moment) testing different nesterov moments with the best learning rate.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{7}{*}{SGD}\n",
      "& 2 & 48.94 ($\\pm$ 38.92) & 1.38 ($\\pm$ 0.92) \\\\ \n",
      "& 1 & 89.07 ($\\pm$ 0.04) & 0.45 ($\\pm$ 0.00) \\\\ \n",
      "& 0.5 & 89.64 ($\\pm$ 0.32) & 0.45 ($\\pm$ 0.01) \\\\ \n",
      "& 0.25 & 90.48 ($\\pm$ 0.23) & 0.39 ($\\pm$ 0.01) \\\\ \n",
      "& 0.05 & 90.00 ($\\pm$ 0.12) & 0.45 ($\\pm$ 0.01) \\\\ \n",
      "& 0.01 & 86.41 ($\\pm$ 0.23) & 0.53 ($\\pm$ 0.03) \\\\ \n",
      "& 0.001 & 79.12 ($\\pm$ 0.21) & 0.62 ($\\pm$ 0.00) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{7}{*}{SGD Momentum}\n",
      "& 2 & 10.12 ($\\pm$ 0.06) & 2.57 ($\\pm$ 0.07) \\\\ \n",
      "& 1 & 10.02 ($\\pm$ 0.03) & 2.40 ($\\pm$ 0.08) \\\\ \n",
      "& 0.5 & 28.96 ($\\pm$ 19.08) & 1.84 ($\\pm$ 0.47) \\\\ \n",
      "& 0.25 & 48.54 ($\\pm$ 38.54) & 1.39 ($\\pm$ 0.92) \\\\ \n",
      "& 0.05 & 91.08 ($\\pm$ 0.44) & 0.36 ($\\pm$ 0.01) \\\\ \n",
      "& 0.01 & 90.58 ($\\pm$ 0.23) & 0.40 ($\\pm$ 0.02) \\\\ \n",
      "& 0.001 & 86.54 ($\\pm$ 0.34) & 0.52 ($\\pm$ 0.02) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{7}{*}{SGD Nesterov}\n",
      "& 2 & 10.04 ($\\pm$ 0.00) & 2.56 ($\\pm$ 0.21) \\\\ \n",
      "& 1 & 10.06 ($\\pm$ 0.03) & 2.41 ($\\pm$ 0.05) \\\\ \n",
      "& 0.5 & 10.02 ($\\pm$ 0.04) & 2.31 ($\\pm$ 0.00) \\\\ \n",
      "& 0.25 & 86.06 ($\\pm$ 0.09) & 0.55 ($\\pm$ 0.03) \\\\ \n",
      "& 0.05 & 90.85 ($\\pm$ 0.29) & 0.37 ($\\pm$ 0.00) \\\\ \n",
      "& 0.01 & 90.52 ($\\pm$ 0.27) & 0.40 ($\\pm$ 0.00) \\\\ \n",
      "& 0.001 & 86.29 ($\\pm$ 0.23) & 0.52 ($\\pm$ 0.00) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tests varying the learning rate and fixed momentum \n",
    "\n",
    "sgd_no_momentum = sgd_experiments.filter_parameters({'sgd_momentum':False})\n",
    "\n",
    "sgd_momentum = sgd_experiments.filter_parameters({'sgd_momentum':0.9,\n",
    "                                                  'sgd_nesterov':False})\n",
    "\n",
    "sgd_nesterov = sgd_experiments.filter_parameters({'sgd_momentum':0.9,\n",
    "                                                  'sgd_nesterov':True})\n",
    "\n",
    "experiment_list = [sgd_no_momentum, sgd_momentum, sgd_nesterov]\n",
    "names_list = ['SGD', 'SGD Momentum', 'SGD Nesterov']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='sgd_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{5}{*}{SGD Nesterov}\n",
      "& 0.1 & 89.92 ($\\pm$ 0.43) & 0.45 ($\\pm$ 0.01) \\\\ \n",
      "& 0.3 & 90.31 ($\\pm$ 0.13) & 0.42 ($\\pm$ 0.00) \\\\ \n",
      "& 0.5 & 90.50 ($\\pm$ 0.23) & 0.41 ($\\pm$ 0.01) \\\\ \n",
      "& 0.7 & 90.84 ($\\pm$ 0.13) & 0.39 ($\\pm$ 0.01) \\\\ \n",
      "& 0.9 & 90.85 ($\\pm$ 0.29) & 0.37 ($\\pm$ 0.00) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tests varying the momentum and fixing the learning rate.\n",
    "\n",
    "sgd_test_momentum = sgd_experiments.filter_parameters({'sgd_lr':0.05, 'sgd_nesterov':True})\n",
    "sgd_test_momentum.sort_by_parameter('sgd_momentum', reverse=False)\n",
    "\n",
    "print(sgd_test_momentum.make_latex_table(parameter='sgd_momentum', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name='SGD Nesterov',\n",
    "                                      precision=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# adam experiments\n",
    "\n",
    "adam_experiments = full_experiment.filter_parameters({'training_method': 'adam',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all adam experiments\n",
    "\n",
    "print(adam_experiments.len)\n",
    "\n",
    "# for experiment in adam_experiments.list:\n",
    "#     print(experiment.parameters_dict)\n",
    "#     print('\\n')\n",
    "    \n",
    "    \n",
    "# 12 tests 6 with amsgrad and 6 without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{6}{*}{ADAM}\n",
      "& 0.005 & 90.365 ($\\pm$ 0.255) & 0.408 ($\\pm$ 0.007) \\\\ \n",
      "& 0.001 & 91.080 ($\\pm$ 0.10) & 0.382 ($\\pm$ 0.004) \\\\ \n",
      "& 0.0005 & 91.130 ($\\pm$ 0.340) & 0.380 ($\\pm$ 0.020) \\\\ \n",
      "& 0.0003 & 90.995 ($\\pm$ 0.045) & 0.388 ($\\pm$ 0.018) \\\\ \n",
      "& 0.0001 & 88.775 ($\\pm$ 0.125) & 0.455 ($\\pm$ 0.002) \\\\ \n",
      "& 5e-05 & 86.190 ($\\pm$ 0.190) & 0.529 ($\\pm$ 0.009) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{6}{*}{ADAM amsgrad}\n",
      "& 0.005 & 90.610 ($\\pm$ 0.230) & 0.403 ($\\pm$ 0.014) \\\\ \n",
      "& 0.001 & 91.030 ($\\pm$ 0.270) & 0.380 ($\\pm$ 0.010) \\\\ \n",
      "& 0.0005 & 91.20 ($\\pm$ 0.290) & 0.379 ($\\pm$ 0.009) \\\\ \n",
      "& 0.0003 & 90.895 ($\\pm$ 0.105) & 0.385 ($\\pm$ 0.011) \\\\ \n",
      "& 0.0001 & 87.970 ($\\pm$ 0.050) & 0.466 ($\\pm$ 0.002) \\\\ \n",
      "& 5e-05 & 85.570 ($\\pm$ 0.140) & 0.548 ($\\pm$ 0.009) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "adam_amsgrad = adam_experiments.filter_parameters({'adam_amsgrad':True})\n",
    "\n",
    "adam_no_amsgrad = adam_experiments.filter_parameters({'adam_amsgrad':False})\n",
    "\n",
    "experiment_list = [adam_no_amsgrad, adam_amsgrad]\n",
    "names_list = ['ADAM', 'ADAM amsgrad']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='adam_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# rmsprop experiments\n",
    "\n",
    "rmsprop_experiments = full_experiment.filter_parameters({'training_method': 'rmsprop',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all rmsprop experiments\n",
    "\n",
    "print(rmsprop_experiments.len)\n",
    "    \n",
    "# 12 tests 6 with centered rmsprop and 6 without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{6}{*}{RMSPROP}\n",
      "& 0.01 & 89.850 ($\\pm$ 0.010) & 0.421 ($\\pm$ 0.001) \\\\ \n",
      "& 0.005 & 90.020 ($\\pm$ 0.170) & 0.430 ($\\pm$ 0.018) \\\\ \n",
      "& 0.001 & 90.805 ($\\pm$ 0.155) & 0.410 ($\\pm$ 0.003) \\\\ \n",
      "& 0.0005 & 90.950 ($\\pm$ 0.080) & 0.386 ($\\pm$ 0.011) \\\\ \n",
      "& 0.0003 & 90.610 ($\\pm$ 0.250) & 0.402 ($\\pm$ 0.005) \\\\ \n",
      "& 0.0001 & 89.210 ($\\pm$ 0.010) & 0.458 ($\\pm$ 0.014) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{6}{*}{RMSPROP centered}\n",
      "& 0.01 & 90.305 ($\\pm$ 0.215) & 0.434 ($\\pm$ 0.003) \\\\ \n",
      "& 0.005 & 90.370 ($\\pm$ 0.140) & 0.433 ($\\pm$ 0.015) \\\\ \n",
      "& 0.001 & 90.655 ($\\pm$ 0.425) & 0.412 ($\\pm$ 0.009) \\\\ \n",
      "& 0.0005 & 90.720 ($\\pm$ 0.030) & 0.386 ($\\pm$ 0.013) \\\\ \n",
      "& 0.0003 & 90.815 ($\\pm$ 0.215) & 0.408 ($\\pm$ 0.018) \\\\ \n",
      "& 0.0001 & 88.955 ($\\pm$ 0.045) & 0.465 ($\\pm$ 0.003) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmsprop_centered = rmsprop_experiments.filter_parameters({'rmsprop_centered':True})\n",
    "\n",
    "rsmprop_not_centered = rmsprop_experiments.filter_parameters({'rmsprop_centered':False})\n",
    "\n",
    "experiment_list = [rsmprop_not_centered, rmsprop_centered]\n",
    "names_list = ['RMSPROP', 'RMSPROP centered']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='rmsprop_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# adagrad experiments\n",
    "\n",
    "adagrad_experiments = full_experiment.filter_parameters({'training_method': 'adagrad',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(adagrad_experiments.len)\n",
    "\n",
    "# for experiment in adagrad_experiments.list:\n",
    "#     print(experiment.parameters_dict)\n",
    "#     print('\\n')\n",
    "    \n",
    "# 5 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{5}{*}{ADAGRAD}\n",
      "& 0.1 & 89.190 ($\\pm$ 0.160) & 0.447 ($\\pm$ 0.017) \\\\ \n",
      "& 0.05 & 89.40 ($\\pm$ 0.310) & 0.425 ($\\pm$ 0.005) \\\\ \n",
      "& 0.01 & 88.770 ($\\pm$ 0.090) & 0.440 ($\\pm$ 0.014) \\\\ \n",
      "& 0.0075 & 88.395 ($\\pm$ 0.025) & 0.440 ($\\pm$ 0.011) \\\\ \n",
      "& 0.005 & 87.805 ($\\pm$ 0.095) & 0.452 ($\\pm$ 0.006) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_list = [adagrad_experiments]\n",
    "names_list = ['ADAGRAD']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='adagrad_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "# TAS experiments\n",
    "\n",
    "tas_experiments = full_experiment.filter_parameters({'training_method': 'sgd',\n",
    "                                                    'learning_method':'tas'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(tas_experiments.len)\n",
    "\n",
    "# for experiment in tas_experiments.list:\n",
    "#     print(experiment.parameters_dict['epochs])\n",
    "#     print('\\n')\n",
    "    \n",
    "# 63 tests, 9 for each epoch selected(100, 50, 25, 15, 10, 5. 100 repets twice. we will disconsidere the first batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tas_alpha': 10, 'tas_beta': 0.3, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 10, 'tas_beta': 0.5, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 10, 'tas_beta': 0.7, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 25, 'tas_beta': 0.3, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 25, 'tas_beta': 0.5, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 25, 'tas_beta': 0.7, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 50, 'tas_beta': 0.3, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 50, 'tas_beta': 0.5, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "{'tas_alpha': 50, 'tas_beta': 0.7, 'tas_gamma': 0.02, 'sgd_lr': 0.05, 'sgd_momentum': 0.9, 'sgd_weight_decay': 0, 'sgd_dampening': 0, 'sgd_nesterov': True, 'architecture': 'vgg19bn_', 'dataset': 'cifar10', 'combine_datasets': False, 'do_validation_set': False, 'epochs': 100, 'batch_size': 128, 'test_set_split': 0.1666667, 'validation_set_split': 0.0, 'reduce_train_set': 1.0, 'executions': 2, 'base_seed': 1230, 'training_method': 'sgd', 'learning_method': 'tas', 'bach_size': 128}\n",
      "\\multirow{18}{*}{TAS}\n",
      " & 10 & 0.3 & 91.08 ($\\pm$ 0.01) & 0.38 ($\\pm$ 0.01) \\\\ \n",
      " & 10 & 0.5 & 91.52 ($\\pm$ 0.27) & 0.37 ($\\pm$ 0.01) \\\\ \n",
      " & 10 & 0.7 & 91.74 ($\\pm$ 0.24) & 0.38 ($\\pm$ 0.01) \\\\ \n",
      " & 25 & 0.3 & 91.24 ($\\pm$ 0.00) & 0.36 ($\\pm$ 0.00) \\\\ \n",
      " & 25 & 0.5 & 91.74 ($\\pm$ 0.12) & 0.36 ($\\pm$ 0.01) \\\\ \n",
      " & 25 & 0.7 & 91.97 ($\\pm$ 0.08) & 0.36 ($\\pm$ 0.01) \\\\ \n",
      " & 50 & 0.3 & 91.47 ($\\pm$ 0.02) & 0.34 ($\\pm$ 0.00) \\\\ \n",
      " & 50 & 0.5 & 91.56 ($\\pm$ 0.20) & 0.38 ($\\pm$ 0.01) \\\\ \n",
      " & 50 & 0.7 & 91.74 ($\\pm$ 0.04) & 0.38 ($\\pm$ 0.01) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tas_100 = tas_experiments.filter_parameters({'epochs':100})\n",
    "tas_100.list = tas_100.list[9:]\n",
    "\n",
    "experiment_list = [tas_100]\n",
    "names_list = ['TAS']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "    print(experiment.make_latex_table(parameter_list=['tas_alpha', 'tas_beta'], \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tas_alpha': 10, 'tas_beta': 0.3, 'tas_gamma': 0.02}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (epoch: 100, execution: 2)\n",
       "Coordinates:\n",
       "  * epoch          (epoch) int64 1 2 3 4 5 6 7 8 9 ... 93 94 95 96 97 98 99 100\n",
       "  * execution      (execution) int64 1 2\n",
       "Data variables:\n",
       "    train_acc1     (execution, epoch) float64 20.88 34.13 46.56 ... 99.88 99.87\n",
       "    val_acc1       (execution, epoch) float64 27.54 39.53 50.22 ... 90.97 90.79\n",
       "    train_loss     (execution, epoch) float64 2.196 1.73 1.447 ... 0.003 0.004\n",
       "    val_loss       (execution, epoch) float64 1.907 1.654 1.377 ... 0.617 0.608\n",
       "    learning_rate  (execution, epoch) float64 0.04768 0.04744 ... 0.001049"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tas_experiments.list[9].learning_method_parameters)\n",
    "tas_experiments.list[9].results_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{18}{*}{TAS}\n",
      "& 10 & 91.065 ($\\pm$ 0.155) & 0.376 ($\\pm$ 0.003) \\\\ \n",
      "& 10 & 91.445 ($\\pm$ 0.145) & 0.386 ($\\pm$ 0.003) \\\\ \n",
      "& 10 & 91.535 ($\\pm$ 0.135) & 0.376 ($\\pm$ 0.011) \\\\ \n",
      "& 25 & 91.205 ($\\pm$ 0.455) & 0.366 ($\\pm$ 0.004) \\\\ \n",
      "& 25 & 91.50 ($\\pm$ 0.10) & 0.375 ($\\pm$ 0.009) \\\\ \n",
      "& 25 & 91.705 ($\\pm$ 0.175) & 0.374 ($\\pm$ 0.001) \\\\ \n",
      "& 50 & 91.045 ($\\pm$ 0.235) & 0.374 ($\\pm$ 0.001) \\\\ \n",
      "& 50 & 91.465 ($\\pm$ 0.025) & 0.372 ($\\pm$ 0.018) \\\\ \n",
      "& 50 & 91.640 ($\\pm$ 0.320) & 0.371 ($\\pm$ 0.003) \\\\ \n",
      "& 10 & 91.080 ($\\pm$ 0.010) & 0.382 ($\\pm$ 0.008) \\\\ \n",
      "& 10 & 91.525 ($\\pm$ 0.275) & 0.369 ($\\pm$ 0.008) \\\\ \n",
      "& 10 & 91.740 ($\\pm$ 0.240) & 0.381 ($\\pm$ 0.007) \\\\ \n",
      "& 25 & 91.235 ($\\pm$ 0.005) & 0.362 ($\\pm$ 0.003) \\\\ \n",
      "& 25 & 91.735 ($\\pm$ 0.125) & 0.362 ($\\pm$ 0.011) \\\\ \n",
      "& 25 & 91.970 ($\\pm$ 0.080) & 0.364 ($\\pm$ 0.007) \\\\ \n",
      "& 50 & 91.470 ($\\pm$ 0.020) & 0.345 ($\\pm$ 0.004) \\\\ \n",
      "& 50 & 91.560 ($\\pm$ 0.20) & 0.379 ($\\pm$ 0.008) \\\\ \n",
      "& 50 & 91.745 ($\\pm$ 0.035) & 0.380 ($\\pm$ 0.011) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_list = [tas_experiments]\n",
    "names_list = ['TAS']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='tas_alpha', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{25}{*}{SGD Momentum}\n",
      "& 2 & 10.04 ($\\pm$ 0.00) \\\\ \n",
      "& 2 & 10.12 ($\\pm$ 0.06) \\\\ \n",
      "& 1 & 10.06 ($\\pm$ 0.03) \\\\ \n",
      "& 1 & 10.02 ($\\pm$ 0.03) \\\\ \n",
      "& 0.5 & 10.02 ($\\pm$ 0.04) \\\\ \n",
      "& 0.5 & 28.96 ($\\pm$ 19.08) \\\\ \n",
      "& 0.25 & 86.06 ($\\pm$ 0.09) \\\\ \n",
      "& 0.25 & 48.54 ($\\pm$ 38.54) \\\\ \n",
      "& 0.05 & 90.85 ($\\pm$ 0.29) \\\\ \n",
      "& 0.05 & 91.08 ($\\pm$ 0.44) \\\\ \n",
      "& 0.01 & 90.52 ($\\pm$ 0.27) \\\\ \n",
      "& 0.01 & 90.58 ($\\pm$ 0.23) \\\\ \n",
      "& 0.001 & 86.29 ($\\pm$ 0.23) \\\\ \n",
      "& 0.001 & 86.54 ($\\pm$ 0.34) \\\\ \n",
      "& 2 & 48.94 ($\\pm$ 38.92) \\\\ \n",
      "& 1 & 89.07 ($\\pm$ 0.04) \\\\ \n",
      "& 0.5 & 89.64 ($\\pm$ 0.32) \\\\ \n",
      "& 0.25 & 90.48 ($\\pm$ 0.23) \\\\ \n",
      "& 0.05 & 90.00 ($\\pm$ 0.12) \\\\ \n",
      "& 0.01 & 86.41 ($\\pm$ 0.23) \\\\ \n",
      "& 0.001 & 79.12 ($\\pm$ 0.21) \\\\ \n",
      "& 0.05 & 89.92 ($\\pm$ 0.43) \\\\ \n",
      "& 0.05 & 90.31 ($\\pm$ 0.13) \\\\ \n",
      "& 0.05 & 90.50 ($\\pm$ 0.23) \\\\ \n",
      "& 0.05 & 90.84 ($\\pm$ 0.13) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sgd_experiments.make_latex_table(parameter='sgd_lr', \n",
    "                                       result_list=['val_acc1', 'val_loss'],\n",
    "                                       result_type_list=['max_mean'],\n",
    "                                       name='SGD Momentum',\n",
    "                                       precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- EXPERIMENT 0 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  2\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.326\n",
      "val_acc1 10.04\n",
      "---------- EXPERIMENT 1 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  2\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.212\n",
      "val_acc1 10.120000000000001\n",
      "---------- EXPERIMENT 2 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  1\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.258\n",
      "val_acc1 10.059999999999999\n",
      "---------- EXPERIMENT 3 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  1\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.428\n",
      "val_acc1 10.025\n",
      "---------- EXPERIMENT 4 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.5\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.332\n",
      "val_acc1 10.025\n",
      "---------- EXPERIMENT 5 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.5\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 26.918\n",
      "val_acc1 28.965\n",
      "---------- EXPERIMENT 6 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.25\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 93.753\n",
      "val_acc1 86.065\n",
      "---------- EXPERIMENT 7 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.25\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 51.689\n",
      "val_acc1 48.54\n",
      "---------- EXPERIMENT 8 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.544\n",
      "val_acc1 90.85\n",
      "---------- EXPERIMENT 9 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.555\n",
      "val_acc1 91.08\n",
      "---------- EXPERIMENT 10 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.01\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.458\n",
      "val_acc1 90.52000000000001\n",
      "---------- EXPERIMENT 11 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.01\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.487\n",
      "val_acc1 90.575\n",
      "---------- EXPERIMENT 12 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.001\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.459\n",
      "val_acc1 86.29499999999999\n",
      "---------- EXPERIMENT 13 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.001\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.42099999999999\n",
      "val_acc1 86.54499999999999\n",
      "---------- EXPERIMENT 14 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  2\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 52.719\n",
      "val_acc1 48.94\n",
      "---------- EXPERIMENT 15 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  1\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.68299999999999\n",
      "val_acc1 89.07\n",
      "---------- EXPERIMENT 16 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.5\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.05799999999999\n",
      "val_acc1 89.63499999999999\n",
      "---------- EXPERIMENT 17 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.25\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.489\n",
      "val_acc1 90.475\n",
      "---------- EXPERIMENT 18 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.42699999999999\n",
      "val_acc1 90.005\n",
      "---------- EXPERIMENT 19 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.01\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.40899999999999\n",
      "val_acc1 86.41\n",
      "---------- EXPERIMENT 20 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.001\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 82.906\n",
      "val_acc1 79.12\n",
      "---------- EXPERIMENT 21 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.1\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.44200000000001\n",
      "val_acc1 89.91499999999999\n",
      "---------- EXPERIMENT 22 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.3\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.486\n",
      "val_acc1 90.31\n",
      "---------- EXPERIMENT 23 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.5\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.476\n",
      "val_acc1 90.5\n",
      "---------- EXPERIMENT 24 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.7\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.55600000000001\n",
      "val_acc1 90.83500000000001\n"
     ]
    }
   ],
   "source": [
    "sgd_experiments.show_results('T&L', ['train_acc1', 'val_acc1'], ['max_mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.SingleExperiment at 0x7f558806fc18>,\n",
       " <__main__.SingleExperiment at 0x7f558806f748>,\n",
       " <__main__.SingleExperiment at 0x7f555d11d550>,\n",
       " <__main__.SingleExperiment at 0x7f555d11deb8>,\n",
       " <__main__.SingleExperiment at 0x7f555d123710>,\n",
       " <__main__.SingleExperiment at 0x7f555d12c0f0>,\n",
       " <__main__.SingleExperiment at 0x7f555d12cd68>,\n",
       " <__main__.SingleExperiment at 0x7f555d11d3c8>,\n",
       " <__main__.SingleExperiment at 0x7f555d12ff28>,\n",
       " <__main__.SingleExperiment at 0x7f555d1358d0>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c0128>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c0dd8>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c5080>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c0978>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c5dd8>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d0160>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d0c88>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d60b8>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d6a20>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d6a90>,\n",
       " <__main__.SingleExperiment at 0x7f555d0da8d0>,\n",
       " <__main__.SingleExperiment at 0x7f555d0daf60>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d0320>,\n",
       " <__main__.SingleExperiment at 0x7f555d0e2198>,\n",
       " <__main__.SingleExperiment at 0x7f555d0e2d30>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_experiments.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':'1', 'b':'2'}\n",
    "for key, value in a.items():\n",
    "    a[key] = int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{1}'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{{{}}}'.format(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
