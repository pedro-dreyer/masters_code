{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "RESULTS_NAMES = ['train_acc1', 'val_acc1', 'train_loss', 'val_loss', 'learning_rate']\n",
    "\n",
    "\n",
    "class FullExperiment:\n",
    "\n",
    "    def __init__(self, folder_path=None, experiment_list=None):\n",
    "\n",
    "        # TODO error if both inputs are None or not None\n",
    "        # if folder_path is None and experiment_list is None:\n",
    "\n",
    "        if folder_path is not None:\n",
    "            self.list = load_experiments(folder_path)\n",
    "        if experiment_list is not None:\n",
    "            self.list = experiment_list\n",
    "\n",
    "        self.len = len(self.list)\n",
    "\n",
    "    def filter_parameters(self, parameters_dict):\n",
    "        new_list = []\n",
    "        for experiment in self.list:\n",
    "            include = True\n",
    "            for parameter, value in parameters_dict.items():\n",
    "                if (parameter not in experiment.parameters_dict.keys() or \n",
    "                        experiment.parameters_dict[parameter] != value):\n",
    "                    include = False\n",
    "                    continue \n",
    "            if include:\n",
    "                new_list.append(experiment)\n",
    "        return FullExperiment(experiment_list=new_list)\n",
    "\n",
    "    def sort_by_parameter(self, parameter, reverse):\n",
    "\n",
    "        # TODO parameter options\n",
    "\n",
    "        def sort_fun(elem):\n",
    "            return elem.parameters_dict[parameter]\n",
    "\n",
    "        self.list.sort(key=sort_fun, reverse=reverse)\n",
    "\n",
    "    def sort_by_results(self, result, metric, reverse):\n",
    "\n",
    "        # TODO result and metric options\n",
    "\n",
    "        def sort_fun(elem):\n",
    "            return elem.get_experiment_summary()[result][metric]\n",
    "\n",
    "        self.list.sort(key=sort_fun, reverse=reverse)\n",
    "\n",
    "    def make_latex_table(self, parameter_list, result_list, result_type_list, name, precision,):\n",
    "\n",
    "        latex_table = '\\\\multirow'\n",
    "        latex_table += '{' + str(self.len) + '}{*}'\n",
    "        latex_table += '{' + name + '}\\n'\n",
    "        \n",
    "        for experiment in self.list:\n",
    "            for parameter in parameter_list:\n",
    "                latex_table += '& ' + str(experiment.parameters_dict[parameter])\n",
    "\n",
    "            experiment_summary = experiment.experiment_results()\n",
    "            for result, result_type in zip(result_list, result_type_list):\n",
    "                result_value = experiment_summary[result][result_type]\n",
    "                result_str = str(result_value.round(precision));\n",
    "                if len(result_str.split('.')[1]) != precision:\n",
    "                    result_str += '0'\n",
    "                \n",
    "                result_str += ' ($\\\\pm$ '\n",
    "                if 'min' in result_type:\n",
    "                    sd_type = 'std_min_mean'\n",
    "                else:\n",
    "                    sd_type = 'std_max_mean'\n",
    "                    \n",
    "                sd_value = experiment_summary[result][sd_type]\n",
    "                sd_str = str(sd_value.round(precision));\n",
    "                if len(sd_str.split('.')[1]) != precision:\n",
    "                    sd_str += '0'\n",
    "\n",
    "                result_str += sd_str + ')'\n",
    "                \n",
    "                latex_table += ' & ' + result_str\n",
    "\n",
    "            latex_table += ' \\\\\\\\ \\n'\n",
    "            \n",
    "        latex_table += '\\\\midrule \\n'\n",
    "\n",
    "        return latex_table\n",
    "    \n",
    "    def show_results(self, parameters, result_names, result_types):\n",
    "        for i_experiment, experiment in enumerate(self.list):\n",
    "            print(10*'-', 'EXPERIMENT {}'.format(i_experiment), 10*'-')\n",
    "            print(3*'*','PARAMETERS', 3*'*')\n",
    "            if parameters == 'all':\n",
    "                \n",
    "                for key, value in experiment.parameters_dict.items():\n",
    "                    print(key,': ', value)\n",
    "            elif parameters == 'training':\n",
    "                print('training method: ', experiment.parameters_dict['training_method'])\n",
    "                for key, value in experiment.training_method_parameters.items():\n",
    "                    print(key, ': ', value) \n",
    "            elif parameters == 'learning':\n",
    "                print('learning method: ', experiment.parameters_dict['learning_method'])\n",
    "                for key, value in experiment.learning_method_parameters.items():\n",
    "                    print(key, ': ', value)\n",
    "            elif parameters == 'T&L':\n",
    "                print('training method: ', experiment.parameters_dict['training_method'])\n",
    "                for key, value in experiment.training_method_parameters.items():\n",
    "                    print(key, ': ', value) \n",
    "                print('learning method: ', experiment.parameters_dict['learning_method'])\n",
    "                for key, value in experiment.learning_method_parameters.items():\n",
    "                    print(key, ': ', value)\n",
    "            else: # parameters is a list\n",
    "                for parameter in parameters:\n",
    "                    print(parameter, ': ', experiment.parameters_dict[parameter])\n",
    "    \n",
    "                \n",
    "            print(3*'*', 'RESULTS', 3*'*')\n",
    "            experiment_results = experiment.experiment_results()\n",
    "            for result_name in result_names:\n",
    "                for result_type in result_types:\n",
    "                    print(result_name, experiment_results[result_name][result_type])\n",
    "            \n",
    "\n",
    "class SingleExperiment:\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.file_name = file_path.split('/')[-1]\n",
    "        self.parameters_dict = get_parameters(file_path)\n",
    "        self.results_df = get_results_pandas(file_path)\n",
    "        self.results_ds = get_results_xarray(file_path)\n",
    "\n",
    "        self.parameters_dict['epochs'] = int(self.parameters_dict['epochs'])\n",
    "        self.parameters_dict['executions'] = int(self.parameters_dict['executions'])\n",
    "\n",
    "        self.parameters_dict['bach_size'] = int(self.parameters_dict['batch_size'])\n",
    "\n",
    "        self.parameters_dict['test_set_split'] = float(self.parameters_dict['test_set_split'])\n",
    "        self.parameters_dict['validation_set_split'] = float(self.parameters_dict['validation_set_split'])\n",
    "        self.parameters_dict['reduce_train_set'] = float(self.parameters_dict['reduce_train_set'])\n",
    "\n",
    "        self.parameters_dict['base_seed'] = int(self.parameters_dict['base_seed'])\n",
    "        \n",
    "        training_method = self.parameters_dict['training_method']\n",
    "        learning_method = self.parameters_dict['learning_method']\n",
    "\n",
    "        self.training_method_parameters = {key: value for key, value\n",
    "                                           in self.parameters_dict.items()\n",
    "                                           if key.split('_')[0] == training_method}\n",
    "\n",
    "        self.learning_method_parameters = {key: value for key, value\n",
    "                                           in self.parameters_dict.items()\n",
    "                                           if key.split('_')[0] == learning_method}\n",
    "        \n",
    "        for key, value in self.parameters_dict.items():\n",
    "            if value == 'False':\n",
    "                self.parameters_dict[key] = False\n",
    "            elif value == 'True':\n",
    "                self.parameters_dict[key] = True\n",
    "\n",
    "    def experiment_results(self, epoch_limit=None):\n",
    "\n",
    "        if epoch_limit is not None:\n",
    "            self.results_ds.drop(range(self.parameters_dict['epochs'], epoch_limit, -1), dim='epoch')\n",
    "\n",
    "        summary_dict = {}\n",
    "        for result in RESULTS_NAMES:\n",
    "            result_da = self.results_ds[result]\n",
    "\n",
    "            mean_da = result_da.mean(dim='execution')\n",
    "            std_da = result_da.std(dim='execution')\n",
    "            max_da = result_da.max(dim='execution')\n",
    "            min_da = result_da.min(dim='execution')\n",
    "\n",
    "            max_mean = mean_da.max(dim='epoch').values\n",
    "            max_mean_epoch = mean_da.argmax(dim='epoch').values + 1\n",
    "            min_mean = mean_da.min(dim='epoch').values\n",
    "            min_mean_epoch = mean_da.argmin(dim='epoch').values + 1\n",
    "\n",
    "            summary = {'mean': mean_da.values, 'std': std_da.values,\n",
    "                       'max': max_da.values, 'min': min_da.values,\n",
    "                       'max_mean': max_mean, 'max_mean_epoch': max_mean_epoch,\n",
    "                       'min_mean': min_mean, 'min_mean_epoch': min_mean_epoch,\n",
    "                       'std_max_mean': std_da.sel(epoch=max_mean_epoch).values,\n",
    "                       'std_min_mean': std_da.sel(epoch=min_mean_epoch).values}\n",
    "\n",
    "            summary_dict[result] = summary\n",
    "\n",
    "        return summary_dict\n",
    "\n",
    "\n",
    "def get_parameters(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        parameters_dict = {}\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line[:-1]\n",
    "\n",
    "            # if we get to a blank line it means that the parameters have ended\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "\n",
    "            colon_position = line.find(':')\n",
    "\n",
    "            if colon_position != -1:\n",
    "                parameter = line[:colon_position]\n",
    "                value = line[colon_position + 1:]\n",
    "                try:\n",
    "                    value = int(value)\n",
    "                except (ValueError, TypeError) as error:\n",
    "                    try:\n",
    "                        value = float(value)\n",
    "                    except (ValueError, TypeError)as error:\n",
    "                        pass\n",
    "\n",
    "                parameters_dict[parameter] = value\n",
    "\n",
    "        return parameters_dict\n",
    "\n",
    "\n",
    "def get_values(file_path, value_name, parameters_dict):\n",
    "    n_epochs = int(parameters_dict['epochs'])\n",
    "    n_executions = int(parameters_dict['executions'])\n",
    "    result = np.empty((n_executions, n_epochs))\n",
    "    i_execution = 0\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        correct_section = False\n",
    "        for line in lines:\n",
    "            line = line[:-1]\n",
    "\n",
    "            if line == value_name:\n",
    "                correct_section = True\n",
    "                continue\n",
    "\n",
    "            if correct_section:\n",
    "                line_list = line.split(',')\n",
    "                if len(line) == 0:\n",
    "                    break\n",
    "                result[i_execution, :] = np.array(line_list, dtype=float)\n",
    "                i_execution += 1\n",
    "        return result\n",
    "\n",
    "\n",
    "def get_results_xarray(file_path):\n",
    "    parameters_dict = get_parameters(file_path)\n",
    "\n",
    "    results_dict = {name: get_values(file_path, name, parameters_dict) for name in RESULTS_NAMES}\n",
    "    n_executions = int(parameters_dict['executions'])\n",
    "    n_epochs = int(parameters_dict['epochs'])\n",
    "\n",
    "    results_ds = xr.Dataset()\n",
    "    for key, value in results_dict.items():\n",
    "        results_ds[key] = (('execution', 'epoch'), value)\n",
    "\n",
    "    results_ds.coords['epoch'] = range(1, n_epochs + 1)\n",
    "    results_ds.coords['execution'] = range(1, n_executions + 1)\n",
    "\n",
    "    # results_df = results_ds.to_dataframe()\n",
    "    # results_df = results_df.swaplevel('epoch', 'execution', axis=0)\n",
    "    # results_df = results_df.sort_index(level=0)\n",
    "\n",
    "    return results_ds\n",
    "\n",
    "\n",
    "def get_results_pandas(file_path):\n",
    "    parameters_dict = get_parameters(file_path)\n",
    "\n",
    "    results_dict = {name: get_values(file_path, name, parameters_dict) for name in RESULTS_NAMES}\n",
    "    n_results = len(RESULTS_NAMES)\n",
    "    n_executions = int(parameters_dict['executions'])\n",
    "    n_epochs = int(parameters_dict['epochs'])\n",
    "\n",
    "    results_array = np.empty((n_results, n_executions, n_epochs))  # results, execution, epoch\n",
    "    for ii, result in enumerate(results_dict.values()):\n",
    "        results_array[ii] = result\n",
    "\n",
    "    results_array = np.swapaxes(results_array, 2, 0)  # epochs, execution, results\n",
    "    results_array = np.swapaxes(results_array, 0, 1)  # execution, epoch, result\n",
    "    results_array = np.reshape(results_array, (n_executions * n_epochs, n_results), order='C')\n",
    "\n",
    "    execution = [ii for ii in range(1, n_executions + 1)]\n",
    "    epochs = [ii for ii in range(1, n_epochs + 1)]\n",
    "    index = pd.MultiIndex.from_product([execution, epochs],\n",
    "                                        names=['execution', 'epoch'])\n",
    "\n",
    "    results_df = pd.DataFrame(results_array,\n",
    "                              index=index,\n",
    "                              columns=RESULTS_NAMES)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def load_experiments(folder_path):\n",
    "    files_name = sorted(os.listdir(folder_path))\n",
    "    # only load .txt files\n",
    "    files_name = list(filter(lambda x: x[-3:] == 'txt', files_name))\n",
    "    files_path = [folder_path + file_name for file_name in files_name]\n",
    "    experiment_list = []\n",
    "    for file_path in files_path:\n",
    "        experiment = SingleExperiment(file_path)\n",
    "        experiment_list.append(experiment)\n",
    "\n",
    "    return experiment_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    folder_path_t = '/home/pedro/PycharmProjects/Masters/new_project/results/first_experiment/data/'\n",
    "    file_name_t = 'sgd_tas-2019-01-12 18:16:22.822506.txt'\n",
    "    file_path_t = folder_path_t + file_name_t\n",
    "    full_experiment = FullExperiment(folder_path=folder_path_t)\n",
    "    sgd_experiments = full_experiment.filter_parameters({'training_method': 'sgd'})\n",
    "\n",
    "\n",
    "    # latex_table = sgd_experiments.make_latex_table('initial_learning_rate', ['val_acc1', 'val_loss'], 'test')\n",
    "    # print(latex_table)\n",
    "\n",
    "\n",
    "    #\n",
    "    # for experiment in full_experiment.list:\n",
    "    #     print(experiment.get_experiment_summary()['val_acc1']['max_mean'])\n",
    "    #\n",
    "    # full_experiment.sort_by_results('val_acc1', 'max_mean', reverse=False)\n",
    "    # print('-------------------------')\n",
    "    # for experiment in full_experiment.list:\n",
    "    #     print(experiment.get_experiment_summary()['val_acc1']['max_mean'])\n",
    "    # #\n",
    "    # # print(full_experiment.list[0].get_experiment_summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_t = '/home/pedro/PycharmProjects/Masters/new_project/results/first_experiment/data/'\n",
    "file_name_t = 'sgd_tas-2019-01-12 18:16:22.822506.txt'\n",
    "file_path_t = folder_path_t + file_name_t\n",
    "full_experiment = FullExperiment(folder_path=folder_path_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# SGD experiments\n",
    "\n",
    "sgd_experiments = full_experiment.filter_parameters({'training_method': 'sgd',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(sgd_experiments.len)\n",
    "\n",
    "\n",
    "# we have 25 experiments in total, 7 for sgd without moment 7 for sgd with moment \n",
    "# 7 for sgd with nesterov moment and more 5 (4 new and 1 already presented among the \n",
    "# 7 from the sgd with nesterov moment) testing different nesterov moments with the best learning rate.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{7}{*}{SGD}\n",
      "& 2 & 48.94 ($\\pm$ 38.92) & 1.38 ($\\pm$ 0.92) \\\\ \n",
      "& 1 & 89.07 ($\\pm$ 0.04) & 0.45 ($\\pm$ 0.00) \\\\ \n",
      "& 0.5 & 89.64 ($\\pm$ 0.32) & 0.45 ($\\pm$ 0.01) \\\\ \n",
      "& 0.25 & 90.48 ($\\pm$ 0.23) & 0.39 ($\\pm$ 0.01) \\\\ \n",
      "& 0.05 & 90.00 ($\\pm$ 0.12) & 0.45 ($\\pm$ 0.01) \\\\ \n",
      "& 0.01 & 86.41 ($\\pm$ 0.23) & 0.53 ($\\pm$ 0.03) \\\\ \n",
      "& 0.001 & 79.12 ($\\pm$ 0.21) & 0.62 ($\\pm$ 0.00) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{7}{*}{SGD Momentum}\n",
      "& 2 & 10.12 ($\\pm$ 0.06) & 2.57 ($\\pm$ 0.07) \\\\ \n",
      "& 1 & 10.02 ($\\pm$ 0.03) & 2.40 ($\\pm$ 0.08) \\\\ \n",
      "& 0.5 & 28.96 ($\\pm$ 19.08) & 1.84 ($\\pm$ 0.47) \\\\ \n",
      "& 0.25 & 48.54 ($\\pm$ 38.54) & 1.39 ($\\pm$ 0.92) \\\\ \n",
      "& 0.05 & 91.08 ($\\pm$ 0.44) & 0.36 ($\\pm$ 0.01) \\\\ \n",
      "& 0.01 & 90.58 ($\\pm$ 0.23) & 0.40 ($\\pm$ 0.02) \\\\ \n",
      "& 0.001 & 86.54 ($\\pm$ 0.34) & 0.52 ($\\pm$ 0.02) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{7}{*}{SGD Nesterov}\n",
      "& 2 & 10.04 ($\\pm$ 0.00) & 2.56 ($\\pm$ 0.21) \\\\ \n",
      "& 1 & 10.06 ($\\pm$ 0.03) & 2.41 ($\\pm$ 0.05) \\\\ \n",
      "& 0.5 & 10.02 ($\\pm$ 0.04) & 2.31 ($\\pm$ 0.00) \\\\ \n",
      "& 0.25 & 86.06 ($\\pm$ 0.09) & 0.55 ($\\pm$ 0.03) \\\\ \n",
      "& 0.05 & 90.85 ($\\pm$ 0.29) & 0.37 ($\\pm$ 0.00) \\\\ \n",
      "& 0.01 & 90.52 ($\\pm$ 0.27) & 0.40 ($\\pm$ 0.00) \\\\ \n",
      "& 0.001 & 86.29 ($\\pm$ 0.23) & 0.52 ($\\pm$ 0.00) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tests varying the learning rate and fixed momentum \n",
    "\n",
    "sgd_no_momentum = sgd_experiments.filter_parameters({'sgd_momentum':False})\n",
    "\n",
    "sgd_momentum = sgd_experiments.filter_parameters({'sgd_momentum':0.9,\n",
    "                                                  'sgd_nesterov':False})\n",
    "\n",
    "sgd_nesterov = sgd_experiments.filter_parameters({'sgd_momentum':0.9,\n",
    "                                                  'sgd_nesterov':True})\n",
    "\n",
    "experiment_list = [sgd_no_momentum, sgd_momentum, sgd_nesterov]\n",
    "names_list = ['SGD', 'SGD Momentum', 'SGD Nesterov']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='sgd_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{5}{*}{SGD Nesterov}\n",
      "& 0.1 & 89.92 ($\\pm$ 0.43) & 0.45 ($\\pm$ 0.01) \\\\ \n",
      "& 0.3 & 90.31 ($\\pm$ 0.13) & 0.42 ($\\pm$ 0.00) \\\\ \n",
      "& 0.5 & 90.50 ($\\pm$ 0.23) & 0.41 ($\\pm$ 0.01) \\\\ \n",
      "& 0.7 & 90.84 ($\\pm$ 0.13) & 0.39 ($\\pm$ 0.01) \\\\ \n",
      "& 0.9 & 90.85 ($\\pm$ 0.29) & 0.37 ($\\pm$ 0.00) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tests varying the momentum and fixing the learning rate.\n",
    "\n",
    "sgd_test_momentum = sgd_experiments.filter_parameters({'sgd_lr':0.05, 'sgd_nesterov':True})\n",
    "sgd_test_momentum.sort_by_parameter('sgd_momentum', reverse=False)\n",
    "\n",
    "print(sgd_test_momentum.make_latex_table(parameter='sgd_momentum', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name='SGD Nesterov',\n",
    "                                      precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# adam experiments\n",
    "\n",
    "adam_experiments = full_experiment.filter_parameters({'training_method': 'adam',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(adam_experiments.len)\n",
    "\n",
    "# for experiment in adam_experiments.list:\n",
    "#     print(experiment.parameters_dict)\n",
    "#     print('\\n')\n",
    "    \n",
    "    \n",
    "# 12 tests 6 with amsgrad and 6 without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{6}{*}{ADAM}\n",
      "& 0.005 & 90.365 ($\\pm$ 0.255) & 0.408 ($\\pm$ 0.007) \\\\ \n",
      "& 0.001 & 91.080 ($\\pm$ 0.10) & 0.382 ($\\pm$ 0.004) \\\\ \n",
      "& 0.0005 & 91.130 ($\\pm$ 0.340) & 0.380 ($\\pm$ 0.020) \\\\ \n",
      "& 0.0003 & 90.995 ($\\pm$ 0.045) & 0.388 ($\\pm$ 0.018) \\\\ \n",
      "& 0.0001 & 88.775 ($\\pm$ 0.125) & 0.455 ($\\pm$ 0.002) \\\\ \n",
      "& 5e-05 & 86.190 ($\\pm$ 0.190) & 0.529 ($\\pm$ 0.009) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{6}{*}{ADAM amsgrad}\n",
      "& 0.005 & 90.610 ($\\pm$ 0.230) & 0.403 ($\\pm$ 0.014) \\\\ \n",
      "& 0.001 & 91.030 ($\\pm$ 0.270) & 0.380 ($\\pm$ 0.010) \\\\ \n",
      "& 0.0005 & 91.20 ($\\pm$ 0.290) & 0.379 ($\\pm$ 0.009) \\\\ \n",
      "& 0.0003 & 90.895 ($\\pm$ 0.105) & 0.385 ($\\pm$ 0.011) \\\\ \n",
      "& 0.0001 & 87.970 ($\\pm$ 0.050) & 0.466 ($\\pm$ 0.002) \\\\ \n",
      "& 5e-05 & 85.570 ($\\pm$ 0.140) & 0.548 ($\\pm$ 0.009) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "adam_amsgrad = adam_experiments.filter_parameters({'adam_amsgrad':True})\n",
    "\n",
    "adam_no_amsgrad = adam_experiments.filter_parameters({'adam_amsgrad':False})\n",
    "\n",
    "experiment_list = [adam_no_amsgrad, adam_amsgrad]\n",
    "names_list = ['ADAM', 'ADAM amsgrad']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='adam_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# rmsprop experiments\n",
    "\n",
    "rmsprop_experiments = full_experiment.filter_parameters({'training_method': 'rmsprop',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(rmsprop_experiments.len)\n",
    "    \n",
    "# 12 tests 6 with centered rmsprop and 6 without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{6}{*}{RMSPROP}\n",
      "& 0.01 & 89.850 ($\\pm$ 0.010) & 0.421 ($\\pm$ 0.001) \\\\ \n",
      "& 0.005 & 90.020 ($\\pm$ 0.170) & 0.430 ($\\pm$ 0.018) \\\\ \n",
      "& 0.001 & 90.805 ($\\pm$ 0.155) & 0.410 ($\\pm$ 0.003) \\\\ \n",
      "& 0.0005 & 90.950 ($\\pm$ 0.080) & 0.386 ($\\pm$ 0.011) \\\\ \n",
      "& 0.0003 & 90.610 ($\\pm$ 0.250) & 0.402 ($\\pm$ 0.005) \\\\ \n",
      "& 0.0001 & 89.210 ($\\pm$ 0.010) & 0.458 ($\\pm$ 0.014) \\\\ \n",
      "\\midrule \n",
      "\n",
      "\\multirow{6}{*}{RMSPROP centered}\n",
      "& 0.01 & 90.305 ($\\pm$ 0.215) & 0.434 ($\\pm$ 0.003) \\\\ \n",
      "& 0.005 & 90.370 ($\\pm$ 0.140) & 0.433 ($\\pm$ 0.015) \\\\ \n",
      "& 0.001 & 90.655 ($\\pm$ 0.425) & 0.412 ($\\pm$ 0.009) \\\\ \n",
      "& 0.0005 & 90.720 ($\\pm$ 0.030) & 0.386 ($\\pm$ 0.013) \\\\ \n",
      "& 0.0003 & 90.815 ($\\pm$ 0.215) & 0.408 ($\\pm$ 0.018) \\\\ \n",
      "& 0.0001 & 88.955 ($\\pm$ 0.045) & 0.465 ($\\pm$ 0.003) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmsprop_centered = rmsprop_experiments.filter_parameters({'rmsprop_centered':True})\n",
    "\n",
    "rsmprop_not_centered = rmsprop_experiments.filter_parameters({'rmsprop_centered':False})\n",
    "\n",
    "experiment_list = [rsmprop_not_centered, rmsprop_centered]\n",
    "names_list = ['RMSPROP', 'RMSPROP centered']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='rmsprop_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# adagrad experiments\n",
    "\n",
    "adagrad_experiments = full_experiment.filter_parameters({'training_method': 'adagrad',\n",
    "                                                    'learning_method':'constant'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(adagrad_experiments.len)\n",
    "\n",
    "# for experiment in adagrad_experiments.list:\n",
    "#     print(experiment.parameters_dict)\n",
    "#     print('\\n')\n",
    "    \n",
    "# 5 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{5}{*}{ADAGRAD}\n",
      "& 0.1 & 89.190 ($\\pm$ 0.160) & 0.447 ($\\pm$ 0.017) \\\\ \n",
      "& 0.05 & 89.40 ($\\pm$ 0.310) & 0.425 ($\\pm$ 0.005) \\\\ \n",
      "& 0.01 & 88.770 ($\\pm$ 0.090) & 0.440 ($\\pm$ 0.014) \\\\ \n",
      "& 0.0075 & 88.395 ($\\pm$ 0.025) & 0.440 ($\\pm$ 0.011) \\\\ \n",
      "& 0.005 & 87.805 ($\\pm$ 0.095) & 0.452 ($\\pm$ 0.006) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_list = [adagrad_experiments]\n",
    "names_list = ['ADAGRAD']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='adagrad_lr', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "# TAS experiments\n",
    "\n",
    "tas_experiments = full_experiment.filter_parameters({'training_method': 'sgd',\n",
    "                                                    'learning_method':'tas'})\n",
    "\n",
    "# see all sgd experiments\n",
    "\n",
    "print(tas_experiments.len)\n",
    "\n",
    "# for experiment in tas_experiments.list:\n",
    "#     print(experiment.parameters_dict['epochs])\n",
    "#     print('\\n')\n",
    "    \n",
    "# 63 tests, 9 for each epoch selected(100, 50, 25, 15, 10, 5. 100 repets twice. we will disconsidere the first batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-4466f0c7ba27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                       \u001b[0mresult_type_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                       precision=2))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-0f58687c2b89>\u001b[0m in \u001b[0;36mmake_latex_table\u001b[0;34m(self, parameter, result_list, result_type_list, name, precision)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mlatex_table\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'& '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mexperiment_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "tas_100 = tas_experiments.filter_parameters({'epochs':100})\n",
    "\n",
    "experiment_list = [tas_100]\n",
    "names_list = ['TAS']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter=['sgd_lr'], \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tas_alpha': 10, 'tas_beta': 0.3, 'tas_gamma': 0.02}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (epoch: 100, execution: 2)\n",
       "Coordinates:\n",
       "  * epoch          (epoch) int64 1 2 3 4 5 6 7 8 9 ... 93 94 95 96 97 98 99 100\n",
       "  * execution      (execution) int64 1 2\n",
       "Data variables:\n",
       "    train_acc1     (execution, epoch) float64 20.88 34.13 46.56 ... 99.88 99.87\n",
       "    val_acc1       (execution, epoch) float64 27.54 39.53 50.22 ... 90.97 90.79\n",
       "    train_loss     (execution, epoch) float64 2.196 1.73 1.447 ... 0.003 0.004\n",
       "    val_loss       (execution, epoch) float64 1.907 1.654 1.377 ... 0.617 0.608\n",
       "    learning_rate  (execution, epoch) float64 0.04768 0.04744 ... 0.001049"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tas_experiments.list[9].learning_method_parameters)\n",
    "tas_experiments.list[9].results_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{18}{*}{TAS}\n",
      "& 10 & 91.065 ($\\pm$ 0.155) & 0.376 ($\\pm$ 0.003) \\\\ \n",
      "& 10 & 91.445 ($\\pm$ 0.145) & 0.386 ($\\pm$ 0.003) \\\\ \n",
      "& 10 & 91.535 ($\\pm$ 0.135) & 0.376 ($\\pm$ 0.011) \\\\ \n",
      "& 25 & 91.205 ($\\pm$ 0.455) & 0.366 ($\\pm$ 0.004) \\\\ \n",
      "& 25 & 91.50 ($\\pm$ 0.10) & 0.375 ($\\pm$ 0.009) \\\\ \n",
      "& 25 & 91.705 ($\\pm$ 0.175) & 0.374 ($\\pm$ 0.001) \\\\ \n",
      "& 50 & 91.045 ($\\pm$ 0.235) & 0.374 ($\\pm$ 0.001) \\\\ \n",
      "& 50 & 91.465 ($\\pm$ 0.025) & 0.372 ($\\pm$ 0.018) \\\\ \n",
      "& 50 & 91.640 ($\\pm$ 0.320) & 0.371 ($\\pm$ 0.003) \\\\ \n",
      "& 10 & 91.080 ($\\pm$ 0.010) & 0.382 ($\\pm$ 0.008) \\\\ \n",
      "& 10 & 91.525 ($\\pm$ 0.275) & 0.369 ($\\pm$ 0.008) \\\\ \n",
      "& 10 & 91.740 ($\\pm$ 0.240) & 0.381 ($\\pm$ 0.007) \\\\ \n",
      "& 25 & 91.235 ($\\pm$ 0.005) & 0.362 ($\\pm$ 0.003) \\\\ \n",
      "& 25 & 91.735 ($\\pm$ 0.125) & 0.362 ($\\pm$ 0.011) \\\\ \n",
      "& 25 & 91.970 ($\\pm$ 0.080) & 0.364 ($\\pm$ 0.007) \\\\ \n",
      "& 50 & 91.470 ($\\pm$ 0.020) & 0.345 ($\\pm$ 0.004) \\\\ \n",
      "& 50 & 91.560 ($\\pm$ 0.20) & 0.379 ($\\pm$ 0.008) \\\\ \n",
      "& 50 & 91.745 ($\\pm$ 0.035) & 0.380 ($\\pm$ 0.011) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_list = [tas_experiments]\n",
    "names_list = ['TAS']\n",
    "\n",
    "\n",
    "for name,experiment in zip(names_list, experiment_list):\n",
    "    \n",
    "\n",
    "    print(experiment.make_latex_table(parameter='tas_alpha', \n",
    "                                      result_list=['val_acc1', 'val_loss'],\n",
    "                                      result_type_list=['max_mean', 'min_mean'],\n",
    "                                      name=name,\n",
    "                                      precision=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{25}{*}{SGD Momentum}\n",
      "& 2 & 10.04 ($\\pm$ 0.00) \\\\ \n",
      "& 2 & 10.12 ($\\pm$ 0.06) \\\\ \n",
      "& 1 & 10.06 ($\\pm$ 0.03) \\\\ \n",
      "& 1 & 10.02 ($\\pm$ 0.03) \\\\ \n",
      "& 0.5 & 10.02 ($\\pm$ 0.04) \\\\ \n",
      "& 0.5 & 28.96 ($\\pm$ 19.08) \\\\ \n",
      "& 0.25 & 86.06 ($\\pm$ 0.09) \\\\ \n",
      "& 0.25 & 48.54 ($\\pm$ 38.54) \\\\ \n",
      "& 0.05 & 90.85 ($\\pm$ 0.29) \\\\ \n",
      "& 0.05 & 91.08 ($\\pm$ 0.44) \\\\ \n",
      "& 0.01 & 90.52 ($\\pm$ 0.27) \\\\ \n",
      "& 0.01 & 90.58 ($\\pm$ 0.23) \\\\ \n",
      "& 0.001 & 86.29 ($\\pm$ 0.23) \\\\ \n",
      "& 0.001 & 86.54 ($\\pm$ 0.34) \\\\ \n",
      "& 2 & 48.94 ($\\pm$ 38.92) \\\\ \n",
      "& 1 & 89.07 ($\\pm$ 0.04) \\\\ \n",
      "& 0.5 & 89.64 ($\\pm$ 0.32) \\\\ \n",
      "& 0.25 & 90.48 ($\\pm$ 0.23) \\\\ \n",
      "& 0.05 & 90.00 ($\\pm$ 0.12) \\\\ \n",
      "& 0.01 & 86.41 ($\\pm$ 0.23) \\\\ \n",
      "& 0.001 & 79.12 ($\\pm$ 0.21) \\\\ \n",
      "& 0.05 & 89.92 ($\\pm$ 0.43) \\\\ \n",
      "& 0.05 & 90.31 ($\\pm$ 0.13) \\\\ \n",
      "& 0.05 & 90.50 ($\\pm$ 0.23) \\\\ \n",
      "& 0.05 & 90.84 ($\\pm$ 0.13) \\\\ \n",
      "\\midrule \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sgd_experiments.make_latex_table(parameter='sgd_lr', \n",
    "                                       result_list=['val_acc1', 'val_loss'],\n",
    "                                       result_type_list=['max_mean'],\n",
    "                                       name='SGD Momentum',\n",
    "                                       precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- EXPERIMENT 0 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  2\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.326\n",
      "val_acc1 10.04\n",
      "---------- EXPERIMENT 1 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  2\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.212\n",
      "val_acc1 10.120000000000001\n",
      "---------- EXPERIMENT 2 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  1\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.258\n",
      "val_acc1 10.059999999999999\n",
      "---------- EXPERIMENT 3 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  1\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.428\n",
      "val_acc1 10.025\n",
      "---------- EXPERIMENT 4 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.5\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 10.332\n",
      "val_acc1 10.025\n",
      "---------- EXPERIMENT 5 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.5\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 26.918\n",
      "val_acc1 28.965\n",
      "---------- EXPERIMENT 6 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.25\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 93.753\n",
      "val_acc1 86.065\n",
      "---------- EXPERIMENT 7 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.25\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 51.689\n",
      "val_acc1 48.54\n",
      "---------- EXPERIMENT 8 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.544\n",
      "val_acc1 90.85\n",
      "---------- EXPERIMENT 9 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.555\n",
      "val_acc1 91.08\n",
      "---------- EXPERIMENT 10 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.01\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.458\n",
      "val_acc1 90.52000000000001\n",
      "---------- EXPERIMENT 11 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.01\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.487\n",
      "val_acc1 90.575\n",
      "---------- EXPERIMENT 12 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.001\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.459\n",
      "val_acc1 86.29499999999999\n",
      "---------- EXPERIMENT 13 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.001\n",
      "sgd_momentum :  0.9\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.42099999999999\n",
      "val_acc1 86.54499999999999\n",
      "---------- EXPERIMENT 14 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  2\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 52.719\n",
      "val_acc1 48.94\n",
      "---------- EXPERIMENT 15 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  1\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.68299999999999\n",
      "val_acc1 89.07\n",
      "---------- EXPERIMENT 16 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.5\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.05799999999999\n",
      "val_acc1 89.63499999999999\n",
      "---------- EXPERIMENT 17 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.25\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.489\n",
      "val_acc1 90.475\n",
      "---------- EXPERIMENT 18 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.42699999999999\n",
      "val_acc1 90.005\n",
      "---------- EXPERIMENT 19 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.01\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 98.40899999999999\n",
      "val_acc1 86.41\n",
      "---------- EXPERIMENT 20 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.001\n",
      "sgd_momentum :  0\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  False\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 82.906\n",
      "val_acc1 79.12\n",
      "---------- EXPERIMENT 21 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.1\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.44200000000001\n",
      "val_acc1 89.91499999999999\n",
      "---------- EXPERIMENT 22 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.3\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.486\n",
      "val_acc1 90.31\n",
      "---------- EXPERIMENT 23 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.5\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.476\n",
      "val_acc1 90.5\n",
      "---------- EXPERIMENT 24 ----------\n",
      "*** PARAMETERS ***\n",
      "training method:  sgd\n",
      "sgd_lr :  0.05\n",
      "sgd_momentum :  0.7\n",
      "sgd_weight_decay :  0\n",
      "sgd_dampening :  0\n",
      "sgd_nesterov :  True\n",
      "learning method:  constant\n",
      "*** RESULTS ***\n",
      "train_acc1 99.55600000000001\n",
      "val_acc1 90.83500000000001\n"
     ]
    }
   ],
   "source": [
    "sgd_experiments.show_results('T&L', ['train_acc1', 'val_acc1'], ['max_mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.SingleExperiment at 0x7f558806fc18>,\n",
       " <__main__.SingleExperiment at 0x7f558806f748>,\n",
       " <__main__.SingleExperiment at 0x7f555d11d550>,\n",
       " <__main__.SingleExperiment at 0x7f555d11deb8>,\n",
       " <__main__.SingleExperiment at 0x7f555d123710>,\n",
       " <__main__.SingleExperiment at 0x7f555d12c0f0>,\n",
       " <__main__.SingleExperiment at 0x7f555d12cd68>,\n",
       " <__main__.SingleExperiment at 0x7f555d11d3c8>,\n",
       " <__main__.SingleExperiment at 0x7f555d12ff28>,\n",
       " <__main__.SingleExperiment at 0x7f555d1358d0>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c0128>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c0dd8>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c5080>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c0978>,\n",
       " <__main__.SingleExperiment at 0x7f555d0c5dd8>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d0160>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d0c88>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d60b8>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d6a20>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d6a90>,\n",
       " <__main__.SingleExperiment at 0x7f555d0da8d0>,\n",
       " <__main__.SingleExperiment at 0x7f555d0daf60>,\n",
       " <__main__.SingleExperiment at 0x7f555d0d0320>,\n",
       " <__main__.SingleExperiment at 0x7f555d0e2198>,\n",
       " <__main__.SingleExperiment at 0x7f555d0e2d30>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_experiments.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':'1', 'b':'2'}\n",
    "for key, value in a.items():\n",
    "    a[key] = int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{1}'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{{{}}}'.format(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
